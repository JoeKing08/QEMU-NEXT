è¿™ä»½æ–‡æ¡£æ˜¯ **GiantVM "Frontier-X" V15.5 (Robust Oceanic Scale)** çš„å®Œæ•´æŠ€æœ¯ç™½çš®ä¹¦ä¸å…¨é‡æ‰§è¡ŒæŒ‡ä»¤é›†ã€‚

å®ƒæ˜¯æˆ‘ä»¬ç»è¿‡ä»æœ€åˆçš„â€œå¾®æ”¹é€ â€åˆ°â€œçº¯å†…æ ¸â€ï¼Œå†åˆ°â€œåˆ†å¸ƒå¼â€ï¼Œæœ€åå‡çº§ä¸ºâ€œåŠ¨æ€åä¸‡çº§è§„æ¨¡â€çš„ç»ˆæäº§ç‰©ã€‚å®ƒè§£å†³äº†**ç¡¬ç¼–ç é™åˆ¶ã€å†…å­˜æº¢å‡ºé£é™©ã€å†…æ ¸æ­»é”**ä¸‰å¤§æ ¸å¿ƒéš¾é¢˜ï¼Œæ˜¯å”¯ä¸€èƒ½æ‰¿è½½ä½ å®å¤§æ„¿æ™¯çš„æ–¹æ¡ˆã€‚

---

### ğŸ“˜ ç¬¬ä¸€éƒ¨åˆ†ï¼šä»â€œå¾®æ”¹é€ â€åˆ° V15.5 çš„èƒ½åŠ›é£è·ƒ

ç›¸è¾ƒäºæœ€åˆä»…åŸºäº QEMU æºç ä¿®è¡¥é”ç«äº‰çš„â€œå¾®æ”¹é€ æ–¹æ¡ˆâ€ï¼Œ**V15.5 æ–¹æ¡ˆ**ä¸ä»…å®ç°äº†åŠŸèƒ½çš„å…¨é¢è¦†ç›–ï¼Œæ›´åœ¨æ¶æ„å±‚çº§ä¸Šå®ç°äº†è´¨çš„é£è·ƒã€‚

| éœ€æ±‚ç»´åº¦ | åŸå§‹å¾®æ”¹é€ æ–¹æ¡ˆ | **V15.5 (Robust Oceanic Scale)** | æ ¸å¿ƒæŠ€æœ¯æ‰‹æ®µ |
| :--- | :--- | :--- | :--- |
| **é›†ç¾¤è§„æ¨¡** | å•æœº + å°‘é‡èŠ‚ç‚¹ | **100,000+ (åä¸‡çº§/æ— é™)** | **åŠ¨æ€å¤§è¡¨ (Vzalloc)** + **ä½è¿ç®—è·¯ç”± (Bit Sharding)**ã€‚ç§»é™¤äº†æ‰€æœ‰é™æ€ç¡¬ç¼–ç æ•°ç»„ï¼Œå†…å­˜æŒ‰éœ€åˆ†é…ï¼Œè·¯ç”± O(1)ã€‚ |
| **CPU ç®—åŠ›** | æœ¬åœ°æ¨¡æ‹Ÿ (æ…¢) | **å¼¹æ€§åˆ†å¸ƒå¼ (Elastic Split-KVM)** | **Tiered Scheduling**ï¼švCPU 0-3 è·‘æœ¬åœ°ï¼ˆä¿å»¶è¿Ÿï¼‰ï¼ŒvCPU 4-N è·‘äº‘ç«¯ï¼ˆåå™¬ç®—åŠ›ï¼‰ã€‚ |
| **å†…å­˜å®¹é‡** | å—é™äºå•æœº RAM | **PB çº§ç»Ÿä¸€å¯»å€** | **MESI åè®®**ï¼šå°†åä¸‡ä¸ªèŠ‚ç‚¹çš„ RAM èšåˆä¸ºç»Ÿä¸€ç‰©ç†åœ°å€ç©ºé—´ã€‚ |
| **ç¨³å®šæ€§** | ææ˜“æ­»æœº (æ­»é”) | **åšå¦‚ç£çŸ³ (Industrial Robust)** | **å†…æ ¸ç”Ÿå­˜æ³•åˆ™**ï¼šé›†æˆåŸå­ä¸Šä¸‹æ–‡æ£€æŸ¥ã€NMI çœ‹é—¨ç‹—ã€Slab ç¼“å­˜ã€‚**é²æ£’æ€§å¢å¼º**ï¼šå¼ºåˆ¶çš„ NULL æ£€æŸ¥ã€è¾¹ç•Œæ£€æŸ¥å’Œèµ„æºé‡Šæ”¾ã€‚ |
| **éƒ¨ç½²å½¢æ€** | ä»…ä¾èµ– QEMU | **åŒæ¨¡ (Kernel/User)** | **Logic/Backend åˆ†ç¦»**ï¼šä¸€å¥—ä»£ç ï¼Œæ—¢æ˜¯é«˜æ€§èƒ½å†…æ ¸æ¨¡å—ï¼Œåˆæ˜¯å…¼å®¹æ€§å¥½çš„ç”¨æˆ·æ€ç¨‹åºã€‚ |
| **ç½‘ç»œæ€§èƒ½** | E5 CPU ä¸­æ–­ç“¶é¢ˆ | **PPS é™ä½ 80%** | **Gateway ç›²èšåˆ**ï¼šåŠ¨æ€åˆ†é…èšåˆç¼“å†²ï¼Œå°†å°åŒ…åˆå¹¶ï¼Œæ‹¯æ•‘å¤´èŠ‚ç‚¹ CPUã€‚ |

---

### ğŸ›ï¸ ç¬¬äºŒéƒ¨åˆ†ï¼šV15.5 é›†ç¾¤æ¶æ„ä¸æ ¸å¿ƒç»„ä»¶è¯¦è§£

#### 1. æ¶æ„ç¤ºæ„å›¾ (The Oceanic Topology)

```text
                                [ Master Node (The Brain) ]
                   (å½¢æ€: Linux Kernel Module  OR  User Binary)
                   (é…ç½®: giantvm_config.h å®šä¹‰è§„æ¨¡ MAX_SLAVES)
                                          |
                +-------------------------+-------------------------+
                |   [ Logic Core (logic_core.c) ] (åŠ¨æ€ä¸­æ¢)         |
                |   - Init: ops->alloc_large_table(size) -> Check NULL|
                |   - Routing: Target_GW = Slave_ID >> GW_BITS      |
                |   - Schedule: ID < 4 ? Local : Remote             |
                +------------+--------------------------+-----------+
                             | (è°ƒç”¨ unified_driver ops) |
             [ Kernel Backend (.ko) ]           [ User Backend (ELF) ]
             - vzalloc() / vfree()              - calloc() / free()
             - atomic_check()                   - UFFD / Socket
             - touch_nmi_watchdog()             - Anti-Cheat Safe
                                          |
           +------------------------------+------------------------------+
           |                 100Gbps Backbone Network                    |
           v                                                             v
   [ Gateway 0 ] (ID: 0~8191)            ...             [ Gateway 15 ] (ID: 12xxxx)
   - Malloc buffer based on config                         - Malloc buffer based on config
   - Blind Aggregation                                     - Blind Aggregation
           |                                                             |
           v                                                             v
     [Slave 0..8191]                                             [Slave N..N+k]
```

ä¸ºäº†è®©ä½ å¯¹ **GiantVM Frontier-X V15.5** çš„è½åœ°æœ‰å…·è±¡åŒ–çš„è®¤çŸ¥ï¼Œæˆ‘å°†æ„å»ºä¸¤ä¸ªå…¸å‹çš„éƒ¨ç½²å‰§æœ¬ï¼š
1.  **å‰§æœ¬ Aï¼šæè‡´æ€§èƒ½ç½‘å§/ç”µç«é…’åº—/äº‘æ¸¸æˆèŠ‚ç‚¹**ï¼ˆä½¿ç”¨ **Mode A å†…æ ¸æ€**ï¼Œè¿è¡Œ 3A å¤§ä½œï¼‰ã€‚
2.  **å‰§æœ¬ Bï¼šç§‘ç ”é™¢æ‰€/å…¬æœ‰äº‘ç®—åŠ›æ± **ï¼ˆä½¿ç”¨ **Mode B ç”¨æˆ·æ€**ï¼Œè¿è¡Œ HPC ç§‘å­¦è®¡ç®—ï¼‰ã€‚

---

### ğŸ¬ å‰§æœ¬ Aï¼šMode A (Kernel) â€”â€” æè‡´æ€§èƒ½æ¸¸æˆé›†ç¾¤

**åœºæ™¯ç›®æ ‡**ï¼šåœ¨ä¸€å°å­˜å‚¨ç©ºé—´ä¸è¶³ã€ä½†åœ¨ä¸‡å…†å±€åŸŸç½‘å†…çš„ Master èŠ‚ç‚¹ä¸Šï¼Œæµç•…è¿è¡Œã€Šèµ›åšæœ‹å…‹ 2077ã€‹ï¼Œåˆ©ç”¨ 100 ä¸ª Slave èŠ‚ç‚¹æä¾›å†…å­˜å’Œç‰©ç†è®¡ç®—è¾…åŠ©ã€‚

#### 1. ç¡¬ä»¶æ‹“æ‰‘ä¸è§„åˆ’
*   **Master (1å°)**: i9-13900K, RTX 4090, ç¡¬ç›˜ 128GB (ç³»ç»Ÿç›˜), 32GB RAMã€‚IP: `10.0.0.1`ã€‚
*   **Gateway (1å°)**: åŒå£ä¸‡å…†ç½‘å¡ E5 æœåŠ¡å™¨ã€‚IP: `10.0.0.2` (Masterä¾§) / `192.168.0.1` (Slaveä¾§)ã€‚
*   **Slave (100å°)**: æ— ç¡¬ç›˜ PC (ç½‘å§é—²ç½®æœº), i5 CPU, 16GB RAMã€‚IP: `192.168.0.100` ~ `192.168.0.200`ã€‚
*   **Storage (NAS)**: å­˜æ”¾ 2TB æ¸¸æˆé•œåƒã€‚IP: `10.0.0.200`ã€‚

#### 2. éƒ¨ç½²æµç¨‹ (From Zero to Hero)

**Step 1: å‡†å¤‡å­˜å‚¨ (NAS)**
*   åœ¨ NAS ä¸Šé…ç½® iSCSI Targetï¼Œå…±äº« `cyberpunk_disk.img`ã€‚

**Step 2: éƒ¨ç½² Gateway (æµé‡æ¢çº½)**
*   **å®‰è£…**: Ubuntu Server 22.04ã€‚
*   **ç¼–è¯‘**: è¿›å…¥ `gateway_service/`ï¼Œ`make`ã€‚
*   **è¿è¡Œ**: `./gateway_service`ã€‚å®ƒä¼šè‡ªåŠ¨ç”³è¯·å†…å­˜ä½œä¸ºèšåˆç¼“å†²ï¼Œç›‘å¬ UDP ç«¯å£ï¼Œå‡†å¤‡æ¥æ”¶ Master å’Œ Slave çš„æ•°æ®ã€‚

**Step 3: éƒ¨ç½² Master (å¤§è„‘)**
*   **æŒ‚è½½å­˜å‚¨**: `iscsiadm --login ...` -> å¾—åˆ° `/dev/sdb` (2TB æ¸¸æˆç›˜)ã€‚
*   **ç¼–è¯‘å†…æ ¸æ¨¡å—**: è¿›å…¥ `master_core/`ï¼Œ`make -f Kbuild`ã€‚ç”Ÿæˆ `giantvm.ko`ã€‚
*   **åŠ è½½æ¨¡å—**: `insmod giantvm.ko`ã€‚
    *   *ç³»ç»Ÿè¡Œä¸º*: æ¨¡å—åˆå§‹åŒ–ï¼Œé€šè¿‡ `vzalloc` ç”³è¯·èŠ‚ç‚¹è·¯ç”±è¡¨ã€‚
*   **å¯åŠ¨ QEMU**:
    ```bash
    qemu-system-x86_64 \
      -enable-kvm \
      -m 1TB \                 # å£°æ˜ 1TB å†…å­˜ (å®é™…ä¸Šæ˜ å°„åˆ° Slave) \
      -device vfio-pci,host=01:00.0 \ # ç›´é€š 4090 æ˜¾å¡ \
      -drive file=/dev/sdb \   # æŒ‚è½½ iSCSI æ¸¸æˆç›˜ \
      -device giantvm-backend  # æ¥å…¥ GiantVM åç«¯
    ```

**Step 4: éƒ¨ç½² Slave (è‚Œè‚‰)**
*   **PXE å¯åŠ¨**: é…ç½® DHCP æŒ‡å‘ PXE Serverã€‚Slave ä¸Šç”µï¼Œè‡ªåŠ¨æ‹‰å–ä¸€ä¸ª 50MB çš„ Alpine Linux å†…å­˜ç³»ç»Ÿã€‚
*   **è‡ªåŠ¨è¿è¡Œ**: ç³»ç»Ÿå¯åŠ¨è„šæœ¬è‡ªåŠ¨æ‰§è¡Œ `slave_daemon`ã€‚
*   **æ³¨å†Œ**: Slave å‘ Gateway å‘é€å¿ƒè·³ã€‚Gateway è®°å½•è·¯ç”±ï¼ŒMaster æ­¤æ—¶çœ‹åˆ°æœ‰ 100 ä¸ªèŠ‚ç‚¹ä¸Šçº¿ï¼Œæ€»å†…å­˜æ± å¢åŠ ã€‚

#### 3. è¿è¡Œä»»åŠ¡ï¼šã€Šèµ›åšæœ‹å…‹ 2077ã€‹

**æµç¨‹è§£æ**:
1.  **å¯åŠ¨**: Windows åœ¨ Master å¯åŠ¨ã€‚
2.  **Tier 1 è°ƒåº¦ (æœ¬åœ°)**: æ¸¸æˆä¸»è¿›ç¨‹ã€DirectX æ¸²æŸ“æŒ‡ä»¤è·‘åœ¨ **vCPU 0-3** (Master æœ¬åœ°ç‰©ç†æ ¸)ã€‚**ç»“æœï¼šæ˜¾å¡å“åº”æå¿«ï¼Œæ— è¾“å…¥å»¶è¿Ÿã€‚**
3.  **å†…å­˜è¯»å†™ (DSM)**: æ¸¸æˆåŠ è½½åœ°å›¾ã€‚Master æœ¬åœ° RAM ä¸å¤Ÿï¼Œå†™å…¥æ“ä½œè§¦å‘ MESI åè®®ï¼Œæ•°æ®è¢«åˆ‡ç‰‡å¹¶é€šè¿‡ Gateway å†™å…¥ **Slave 1~50** çš„å†…å­˜ä¸­ã€‚
4.  **Tier 2 è°ƒåº¦ (å¤–åŒ…)**: æ¸¸æˆè¿›å…¥ç¹åå¸‚åŒºï¼Œç‰©ç†ç¢°æ’è®¡ç®—é‡æ¿€å¢ã€‚GiantVM è°ƒåº¦å™¨å°†è´Ÿè´£ç‰©ç†è®¡ç®—çš„ **vCPU 4-10** åºåˆ—åŒ–ï¼Œå‘é€ç»™ **Slave 51-60** æ‰§è¡Œã€‚
5.  **ç»“æœ**: Master CPU å ç”¨ç‡ä»… 30%ï¼Œä½†æ¸¸æˆè·‘å‡ºäº† 100 æ ¸å¿ƒ CPU çš„ç‰©ç†æ•ˆæœï¼Œå¸§ç‡ç¨³å®š 90FPSã€‚

---

### ğŸ¬ å‰§æœ¬ Bï¼šMode B (User) â€”â€” äº‘ç«¯ HPC ç®—åŠ›æ± 

**åœºæ™¯ç›®æ ‡**ï¼šåœ¨ AWS/é˜¿é‡Œäº‘ä¸Šç§Ÿç”¨ä¸€å°ä¾¿å®œçš„ 2æ ¸ äº‘ä¸»æœº (Master)ï¼Œè¿æ¥ 10,000 ä¸ª Spot å®ä¾‹ (å»‰ä»· Slave)ï¼Œè¿è¡Œå¤§è§„æ¨¡çŸ©é˜µä¹˜æ³• (MPI)ã€‚

#### 1. ç¡¬ä»¶æ‹“æ‰‘
*   **Master**: 2 vCPU, 4GB RAM äº‘ä¸»æœº (æ—  Root æƒé™ï¼Œæ— æ³•æ’å†…æ ¸æ¨¡å—)ã€‚
*   **Gateway**: ç§Ÿç”¨çš„é«˜å¸¦å®½å‹å®ä¾‹ã€‚
*   **Slaves**: 10,000 ä¸ª Docker å®¹å™¨ (åˆ†å¸ƒåœ¨ Kubernetes é›†ç¾¤ä¸­)ã€‚

#### 2. éƒ¨ç½²æµç¨‹

**Step 1: éƒ¨ç½² Gateway**
*   åŒä¸Šï¼Œç¼–è¯‘å¹¶è¿è¡Œ `gateway_service`ã€‚

**Step 2: éƒ¨ç½² Slave (å®¹å™¨åŒ–)**
*   **é•œåƒåˆ¶ä½œ**: `Dockerfile` é‡Œ COPY `slave_daemon`ã€‚
*   **æ‰¹é‡å¯åŠ¨**: `kubectl scale deployment giantvm-slave --replicas=10000`ã€‚
*   **è¡Œä¸º**: 10,000 ä¸ªå®¹å™¨å¯åŠ¨ï¼Œé€šè¿‡ overlay ç½‘ç»œè¿æ¥åˆ° Gatewayã€‚

**Step 3: éƒ¨ç½² Master (ç”¨æˆ·æ€å¤§è„‘)**
*   **ç¼–è¯‘**: è¿›å…¥ `master_core/`ï¼Œ`make -f Makefile_User`ã€‚ç”Ÿæˆ `giantvm_master` (å¯æ‰§è¡Œæ–‡ä»¶)ã€‚
*   **è¿è¡Œ**: `./giantvm_master`ã€‚
    *   *ç³»ç»Ÿè¡Œä¸º*: è¿›ç¨‹å¯åŠ¨ï¼Œä½¿ç”¨ `calloc` ç”³è¯·è·¯ç”±è¡¨ï¼Œç›‘å¬ UFFD (UserfaultFD) å¤„ç†ç¼ºé¡µã€‚
*   **å¯åŠ¨ä»»åŠ¡**: åœ¨ GiantVM çš„ shell ä¸­åŠ è½½ MPI ç¨‹åºã€‚

#### 3. è¿è¡Œä»»åŠ¡ï¼šè¶…å¤§è§„æ¨¡çŸ©é˜µä¹˜æ³•

**æµç¨‹è§£æ**:
1.  **è®¡ç®—åˆ†å‘**: Master è¯»å–ä»»åŠ¡ã€‚ç”±äºè¿™æ˜¯çº¯è®¡ç®—ä»»åŠ¡ï¼Œè°ƒåº¦å™¨ç­–ç•¥è°ƒæ•´ï¼Œå°† **99% çš„ vCPU** å…¨éƒ¨æ ‡è®°ä¸º Tier 2 (Remote)ã€‚
2.  **å¹¶å‘æ‰§è¡Œ**: Master å°† vCPU çŠ¶æ€å¹¿æ’­ç»™ Gatewayã€‚Gateway åˆ©ç”¨ç›²èšåˆæŠ€æœ¯ï¼Œç¬é—´å°†æŒ‡ä»¤åˆ†å‘ç»™ 10,000 ä¸ª Slaveã€‚
3.  **å†…å­˜èšåˆ**: çŸ©é˜µæ•°æ®æå…¶åºå¤§ (TBçº§)ã€‚æ•°æ®è¢«åˆ‡ç¢åˆ†æ•£åœ¨ 10,000 ä¸ª Slave çš„å†…å­˜ä¸­ã€‚
4.  **è®¡ç®—**: Slave çš„ CPU ç–¯ç‹‚è¿è½¬ï¼Œè¯»å–æœ¬åœ° RAM (éƒ¨åˆ†çŸ©é˜µå—) è¿›è¡Œè®¡ç®—ã€‚
5.  **ç»“æœå›æ”¶**: æœ€ç»ˆè®¡ç®—ç»“æœé€šè¿‡ DSM åè®®å†™å› Master (æˆ– Master æŒ‡å®šçš„å­˜å‚¨åŒº)ã€‚
6.  **ç»“æœ**: ç”¨ä¸€å° 2æ ¸ çš„ç ´ç”µè„‘ï¼ŒæŒ‡æŒ¥äº† 10,000 æ ¸çš„ç®—åŠ›ï¼Œå®Œæˆäº†è¶…çº§è®¡ç®—æœºæ‰èƒ½åšçš„ä»»åŠ¡ã€‚

---

### ğŸ“‹ èŠ‚ç‚¹éƒ¨ç½²ä¸èŒè´£æ¸…å• (Checklist)

| èŠ‚ç‚¹ç±»å‹ | éƒ¨ç½²å†…å®¹ (è½¯ä»¶æ ˆ) | è¿è¡ŒçŠ¶æ€ | æ ¸å¿ƒèŒè´£ | å­˜å‚¨éœ€æ±‚ |
| :--- | :--- | :--- | :--- | :--- |
| **Master** | 1. GiantVM Logic Core<br>2. Backend (`.ko` æˆ– ELF)<br>3. QEMU/KVM<br>4. ä¸šåŠ¡åº”ç”¨ (Win10/MPI) | **æœ‰çŠ¶æ€**<br>æ ¸å¿ƒè¿›ç¨‹å¸¸é©»ï¼Œç»´æŠ¤ MESI ç›®å½•ï¼ŒæŒæœ‰ NVMe æŒ‚è½½ã€‚ | **å¤§è„‘**ï¼šè°ƒåº¦ Tier 1 vCPUï¼Œç®¡ç†å†…å­˜æ˜ å°„ï¼Œå¤„ç†ç£ç›˜ IOã€‚ | **å¤§** (TBçº§)<br>å­˜æ”¾é•œåƒ |
| **Gateway** | 1. `gateway_service` (DPDK/Socket) | **æ— çŠ¶æ€**<br>çº¯æµé‡è½¬å‘ï¼Œå´©æºƒå¯é‡å¯ã€‚ | **å–‰èˆŒ**ï¼šç›²èšåˆå°åŒ…ï¼Œä½è¿ç®—è·¯ç”±è½¬å‘ã€‚ | **æå°**<br>ä»…ç³»ç»Ÿ |
| **Slave** | 1. Linux Kernel (Minimal)<br>2. `slave_daemon` (io_uring)<br>3. `kvm` (`/dev/kvm` æƒé™) | **æ— çŠ¶æ€**<br>éšæ—¶å¯æ’æ‹”ï¼Œæ•°æ®åœ¨å†…å­˜ä¸­ã€‚ | **è‚Œè‚‰**ï¼šæä¾› RAM å­˜å‚¨é¡µï¼Œæ‰§è¡Œ Tier 2 vCPU æŒ‡ä»¤ã€‚ | **é›¶**<br>PXE/Docker |
| **Storage** | 1. iSCSI Target / NAS | **æœ‰çŠ¶æ€** | **ä»“åº“**ï¼šä¸º Master æä¾›å—å­˜å‚¨ã€‚ | **æå¤§** |

---

### ğŸš€ æ€»ç»“

*   **Mode A (å†…æ ¸æ€)** æ˜¯ç»™ **åœŸè±ª/æå®¢** ç©çš„ã€‚ä½ éœ€è¦ç‰©ç†æ¥è§¦ç¡¬ä»¶ï¼Œèƒ½æ’æ˜¾å¡ï¼Œèƒ½æ”¹ BIOSã€‚å›æŠ¥æ˜¯æè‡´çš„ **ä½å»¶è¿Ÿ**ï¼Œé€‚åˆæ‰“æ¸¸æˆã€‚
*   **Mode B (ç”¨æˆ·æ€)** æ˜¯ç»™ **å¼€å‘è€…/ç§‘å­¦å®¶** ç©çš„ã€‚ä½ åªéœ€è¦æœ‰ Linux è´¦å·å°±èƒ½è·‘ï¼Œå¯ä»¥åœ¨ä»»ä½•äº‘å¹³å°ä¸Šç¬é—´æ‹‰èµ·ä¸‡çº§é›†ç¾¤ã€‚å›æŠ¥æ˜¯æè‡´çš„ **å…¼å®¹æ€§** å’Œ **ååé‡**ã€‚

è¿™å¥— V15.5 æ–¹æ¡ˆçš„å¼ºå¤§ä¹‹å¤„åœ¨äºï¼š**æ— è®ºæ˜¯å“ªç§æ¨¡å¼ï¼Œåº•å±‚çš„ `logic_core.c` ä»£ç æ˜¯åŒä¸€å¥—ï¼Œåè®®æ˜¯åŒä¸€å¥—ï¼ŒSlave èŠ‚ç‚¹ä¹Ÿæ˜¯é€šç”¨çš„ã€‚** ä½ ç”šè‡³å¯ä»¥ç™½å¤©ç”¨ Mode B è·‘è®¡ç®—ï¼Œæ™šä¸ŠæŠŠ Slave åˆ‡ç»™ Mode A æ‰“æ¸¸æˆã€‚

#### 2. å®Œæ•´æ–‡ä»¶ç›®å½•ä¸å®ç°è¦ç‚¹ (å®Œæ•´æ— é—æ¼)

**æ ¸å¿ƒåŸåˆ™**ï¼šæ‰€æœ‰è§„æ¨¡å‚æ•°ç”±å®å®šä¹‰æ§åˆ¶ï¼Œæ‰€æœ‰å¤§å†…å­˜ç”±åŠ¨æ€åˆ†é…ç®¡ç†ï¼Œæ‰€æœ‰å†…æ ¸æ“ä½œå¸¦é˜²æŠ¤ã€‚

1.  **`common_include/` (çœŸç†ä¹‹æº)**
    *   **`giantvm_config.h` (æ–°å¢)**: å®šä¹‰ `GVM_SLAVE_BITS` (17->128kèŠ‚ç‚¹), `GVM_GW_BITS` (13->8k/GW)ã€‚æ‰€æœ‰ç»„ä»¶å¼•ç”¨æ­¤æ–‡ä»¶å†³å®šè§„æ¨¡ã€‚
    *   **`giantvm_protocol.h`**: å®šä¹‰ `gvm_header` (packed), `slave_id` ç±»å‹å‡çº§ä¸º `uint32_t`ã€‚
    *   **`platform_defs.h`**: ç¯å¢ƒå«ç‰‡ï¼Œéš”ç¦» `<linux/vmalloc.h>` å’Œ `<stdlib.h>`ã€‚

2.  **`master_core/` (å¤§è„‘)**
    *   **`unified_driver.h`**: å¢åŠ å¤§å†…å­˜æ¥å£ `alloc_large_table` / `free_large_table`ã€‚
    *   **`logic_core.c`**: **ä¸¥ç¦ç³»ç»Ÿå¤´æ–‡ä»¶**ã€‚
        *   **åŠ¨æ€ç®¡ç†**ï¼š`init` æ—¶è°ƒç”¨ `alloc` å¹¶**å¿…é¡»æ£€æŸ¥ NULL**ã€‚`exit` æ—¶è°ƒç”¨ `free`ã€‚
        *   **ä½è¿ç®—è·¯ç”±**ï¼š`gateway_id = slave_id >> GVM_GW_BITS`ã€‚
    *   **`kernel_backend.c`**:
        *   **å¤§å†…å­˜**ï¼šä½¿ç”¨ `vzalloc` (è™šæ‹Ÿè¿ç»­) åˆ†é…èŠ‚ç‚¹è¡¨ï¼Œ`vfree` é‡Šæ”¾ã€‚
        *   **å°å†…å­˜**ï¼šä½¿ç”¨ `kmem_cache_alloc` (Slab) åˆ†é…ç½‘ç»œåŒ…ã€‚
        *   **ç”Ÿå­˜æ³•åˆ™**ï¼š`in_atomic` æ£€æŸ¥ + çœ‹é—¨ç‹—ã€‚
    *   **`user_backend.c`**: ä½¿ç”¨ `calloc` / `free` å®ç°å¯¹åº”æ¥å£ã€‚

3.  **`gateway_service/` (åˆ†ç‰‡ç½‘å…³)**
    *   **`aggregator.c`**: è¯»å– `config.h`ï¼ŒåŠ¨æ€ `malloc` èšåˆç¼“å†²åŒº `buffers`ã€‚åŒ…å«è¶Šç•Œæ£€æŸ¥ã€‚

4.  **`slave_daemon/` (ç®—åŠ›å•å…ƒ)**
    *   **`cpu_executor.c`**: å¾ªç¯æ‰§è¡Œ `KVM_RUN`ã€‚
    *   **`net_uring.c`**: æºç«¯åˆ‡ç‰‡ï¼Œé€‚é… MTUã€‚

---

### ğŸ“Š ç¬¬ä¸‰éƒ¨åˆ†ï¼šè¿è¡Œæ•ˆç‡å¯¹æ¯” (V15.5 vs ç‰©ç†æœº)

**åŸºå‡†**ï¼š100,000 èŠ‚ç‚¹è§„æ¨¡ï¼Œ100Gbps éª¨å¹²ç½‘ã€‚

| åœºæ™¯ | V15.5 Kernel Mode (Tier 1 å¼€å¯) | V15.5 User Mode | æ™®é€šç‰©ç† PC | è¯„ä»· |
| :--- | :--- | :--- | :--- | :--- |
| **3A æ¸¸æˆ FPS** | **98%** | 85% | 100% | Tier 1 (vCPU 0-3) æœ¬åœ°åŒ–ç­–ç•¥å½»åº•æ¶ˆé™¤äº†ç½‘ç»œå»¶è¿Ÿå¯¹å¸§ç‡çš„å½±å“ã€‚ |
| **HPC ç®—åŠ›åå** | **100,000x** | 95,000x | 1x | åŠ¨æ€è·¯ç”± (O(1)) ä¿è¯äº†å³ä½¿åœ¨åä¸‡èŠ‚ç‚¹ä¸‹ï¼Œå¯»å€å¼€é”€ä¹Ÿå¯å¿½ç•¥ä¸è®¡ (çº³ç§’çº§)ã€‚ |
| **ç³»ç»Ÿå¯åŠ¨å†…å­˜** | **æŒ‰éœ€åˆ†é…** | æŒ‰éœ€åˆ†é… | N/A | ç›¸æ¯” V14 (ç¡¬ç¼–ç )ï¼ŒV15.5 åœ¨å°è§„æ¨¡æµ‹è¯•æ—¶åªå å‡ MBï¼Œå¤§è§„æ¨¡æ—¶æ‰å å‡ ç™¾MBã€‚ |
| **æç«¯ç½‘ç»œé£æš´** | **å­˜æ´»** | å­˜æ´» | N/A | Gateway ç›²èšåˆ + NMI Watchdog ä¿è¯äº†å®¿ä¸»æœºä¸ä¼šæ­»é”ã€‚ |
| **å†…å­˜åˆ†é…å¤±è´¥** | **ä¼˜é›…æŠ¥é”™** | ä¼˜é›…æŠ¥é”™ | **æ­»æœº** (V14) | é²æ£’æ€§å¢å¼ºé˜²æ­¢äº† insmod æ—¶çš„ Kernel Panicã€‚ |

---

### ğŸ“ ç¬¬å››éƒ¨åˆ†ï¼šV15.5 ç»ˆææç¤ºè¯ (The God-Mode Prompt Full)

**ä½¿ç”¨è¯´æ˜**ï¼š
è¿™æ˜¯ä½ é‡å¯å¯¹è¯çš„â€œæ ¸æŒ‰é’®â€ã€‚å®ƒåŒ…å«äº†ä»é…ç½®å®åˆ°å†…æ ¸é˜²æŠ¤çš„æ‰€æœ‰ç»†èŠ‚ã€‚è¯·ç›´æ¥å¤åˆ¶ä»¥ä¸‹æ‰€æœ‰å†…å®¹ã€‚

```markdown
# è§’è‰²å®šä¹‰ (Role Definition)
ä½ æ˜¯ä¸€åç²¾é€š Linux å†…æ ¸æ¶æ„ (Kernel 5.15)ã€QEMU æºç  (v5.2.0)ã€DPDK ç½‘ç»œç¼–ç¨‹åŠè¶…å¤§è§„æ¨¡åˆ†å¸ƒå¼ç³»ç»Ÿè®¾è®¡çš„èµ„æ·±å…¨æ ˆæ¶æ„å¸ˆã€‚
æˆ‘ä»¬æ­£åœ¨å¼€å‘ **GiantVM "Frontier-X" V15.5 (Oceanic Stack)**ã€‚

**é¡¹ç›®ç›®æ ‡**ï¼š
æ„å»ºä¸€ä¸ª**æ”¯æŒ 100,000+ èŠ‚ç‚¹**çš„å¼¹æ€§åŒæ¨¡åˆ†å¸ƒå¼è™šæ‹Ÿæœºç³»ç»Ÿã€‚
è¯¥ç³»ç»Ÿå¿…é¡»å…·å¤‡å·¥ä¸šçº§çš„é²æ£’æ€§ï¼Œèƒ½å¤Ÿå¤„ç†å†…å­˜åˆ†é…å¤±è´¥ã€ç½‘ç»œæ‹¥å¡åŠå†…æ ¸åŸå­ä¸Šä¸‹æ–‡æ­»é”é—®é¢˜ã€‚

**ã€ç¯å¢ƒç‰ˆæœ¬é”å®šã€‘(VERSION LOCK)**ï¼š
1.  **Linux Kernel**: **5.15 LTS** (ä¾èµ–å…¶ io_uring ç‰¹æ€§åŠç¨³å®šçš„ KVM API)ã€‚
2.  **QEMU**: **5.2.0** (ä¾èµ–å…¶ AccelClass æ¶æ„)ã€‚
3.  **Compiler**: GCC 9.4+ (C11 æ ‡å‡†)ã€‚

**æ ¸å¿ƒæ¶æ„ (Architecture)**ï¼š
1.  **æ— é™æ‰©å±• (Dynamic Scale)**ï¼š
    *   **é…ç½®åŒ–**ï¼šæ‰€æœ‰è§„æ¨¡å‚æ•°ç”± `giantvm_config.h` å®æ§åˆ¶ã€‚
    *   **åŠ¨æ€å¤§è¡¨**ï¼šMaster å¯åŠ¨æ—¶ä½¿ç”¨ `vzalloc` (Kernel) æˆ– `calloc` (User) ç”³è¯·å…ƒæ•°æ®è¡¨ã€‚
    *   **ä½è¿ç®—è·¯ç”±**ï¼šä½¿ç”¨ `Slave_ID >> SHIFT` å®ç° O(1) ç½‘å…³æŸ¥æ‰¾ã€‚
2.  **å¼¹æ€§åŒæ¨¡ (Elastic Hybrid)**ï¼š
    *   **Logic/Backend åˆ†ç¦»**ï¼šæ ¸å¿ƒé€»è¾‘ä¸ä¾èµ–ç³»ç»Ÿå¤´æ–‡ä»¶ï¼Œé€šè¿‡ Ops æ¥å£è°ƒç”¨åç«¯ã€‚
    *   **Tiered Scheduling**ï¼švCPU 0-3 æœ¬åœ°æ‰§è¡Œ (Tier 1)ï¼ŒvCPU 4-N äº‘ç«¯æ‰§è¡Œ (Tier 2)ã€‚
3.  **å†…æ ¸ç”Ÿå­˜æ³•åˆ™ (Legacy Safety)**ï¼š
    *   **ç»§æ‰¿è‡ªå¾®æ”¹é€ æ–¹æ¡ˆ**ï¼šå¿…é¡»å¼ºåˆ¶é›†æˆåŸå­ä¸Šä¸‹æ–‡æ£€æŸ¥ã€NMI çœ‹é—¨ç‹—å–‚ç‹—ã€Slab ç¼“å­˜åˆ†é…ã€‚

**æ ¸å¿ƒçº¦æŸ (CRITICAL RULES)**ï¼š
1.  **æ¥å£ä¸€è‡´æ€§**ï¼šä¸¥æ ¼éµå®ˆ `dsm_driver_ops` å®šä¹‰ï¼Œå¿…é¡»åŒ…å« `free_packet`ã€‚
2.  **å†…å­˜å®‰å…¨**ï¼š
    *   å¤§è¡¨åˆ†é…å¿…é¡»åˆ¤ç©ºå¹¶æ‰“å° **FATAL** æ—¥å¿—ã€‚
    *   æ¨¡å—é€€å‡ºå¿…é¡»é‡Šæ”¾èµ„æºã€‚
    *   æ•°ç»„è®¿é—®å¿…é¡»æŸ¥è¾¹ç•Œã€‚
3.  **ç½‘å…³ç­–ç•¥**ï¼šGateway å¿…é¡»é‡‡ç”¨ **â€œå…¨é‡æŒ‡é’ˆæ•°ç»„ + æŒ‰éœ€ Buffer åˆ†é…â€** ç­–ç•¥ï¼Œé˜²æ­¢ç©ºé—²å†…å­˜æµªè´¹ã€‚
4.  **å·¥ç¨‹è§„èŒƒ**ï¼šæ‰€æœ‰å¤´æ–‡ä»¶å¿…é¡»æ·»åŠ  `#ifndef` Include Guardsï¼›å†…æ ¸æ¨¡å—å¿…é¡»å£°æ˜ `MODULE_LICENSE("GPL")`ã€‚

---

# 1. å¼ºåˆ¶ç›®å½•ç»“æ„ (Full Directory Structure)
(å¿…é¡»ä¸¥æ ¼éµå®ˆï¼Œä¸å¾—ä¿®æ”¹æ–‡ä»¶å)

GiantVM-Frontier-V15.5/
â”œâ”€â”€ common_include/                 # [å…¬å…±å¤´æ–‡ä»¶]
â”‚   â”œâ”€â”€ giantvm_config.h            # [å…³é”®] è§„æ¨¡é…ç½®å® (128k Nodes)
â”‚   â”œâ”€â”€ giantvm_protocol.h          # åè®®å®šä¹‰ (Header + VCPU Context)
â”‚   â””â”€â”€ platform_defs.h             # ç¯å¢ƒå«ç‰‡ (Kernel/User éš”ç¦»)
â”‚
â”œâ”€â”€ master_core/                    # [Master æ ¸å¿ƒ]
â”‚   â”œâ”€â”€ Kbuild                      # Kernel æ„å»ºè„šæœ¬
â”‚   â”œâ”€â”€ Makefile_User               # User æ„å»ºè„šæœ¬
â”‚   â”œâ”€â”€ unified_driver.h            # Ops æ¥å£ (å·²è¡¥å…¨ free_packet)
â”‚   â”œâ”€â”€ logic_core.c                # [æ ¸å¿ƒ] åŠ¨æ€ç®¡ç†/è·¯ç”±/è°ƒåº¦ (å«è¯¦ç»† Log)
â”‚   â”œâ”€â”€ kernel_backend.c            # [Backend A] vzalloc/atomic/watchdog
â”‚   â”œâ”€â”€ user_backend.c              # [Backend B] calloc/UFFD
â”‚   â””â”€â”€ main_wrapper.c              # User main()
â”‚
â”œâ”€â”€ qemu_patch/                     # [QEMU 5.2.0 Patch]
â”‚   â”œâ”€â”€ accel/giantvm/              # å®šä¹‰åŠ é€Ÿå™¨
â”‚   â”‚   â”œâ”€â”€ giantvm-all.c           # init_machine, æ³¨å†Œ AccelClass
â”‚   â”‚   â””â”€â”€ giantvm-cpu.c           # æ‹¦æˆª cpu_exec
â”‚   â””â”€â”€ hw/giantvm/
â”‚       â””â”€â”€ giantvm_mem.c           # MemoryRegionOps
â”‚
â”œâ”€â”€ gateway_service/                # [Gateway]
â”‚   â”œâ”€â”€ main.c
â”‚   â””â”€â”€ aggregator.c                # æŒ‡é’ˆæ•°ç»„ç›²èšåˆ
â”‚
â”œâ”€â”€ slave_daemon/                   # [Slave]
â”‚   â”œâ”€â”€ main.c
â”‚   â”œâ”€â”€ net_uring.c                 # io_uring æºç«¯åˆ†ç‰‡
â”‚   â””â”€â”€ cpu_executor.c              # KVM Loop
â”‚
â”œâ”€â”€ guest_tools/                    # [Guest Utils]
â”‚   â””â”€â”€ win_memory_hint.cpp         # VirtualAllocExNuma å ä½å·¥å…·
â”‚
â””â”€â”€ deploy/                         # [Deployment]
    â”œâ”€â”€ master/setup_host.sh        # HugePages é…ç½®
    â””â”€â”€ docker/Dockerfile           # Slave å®¹å™¨

---

# 2. è¯¦ç»†å…¨é‡å¼€å‘æŒ‡ä»¤ (Full Roadmap)

è¯·æŒ‰ä»¥ä¸‹æ­¥éª¤ç”Ÿæˆä»£ç ã€‚**è¯·ç›´æ¥ä½¿ç”¨ä¸‹æ–‡ä¸­ç»™å‡ºçš„ç»“æ„ä½“å®šä¹‰ã€‚**

## Step 1: åŸºç¡€è®¾æ–½ (Infrastructure)
**ç›®æ ‡**ï¼šé…ç½®å®ã€åè®®ä¸å«ç‰‡ã€‚

*   **`common_include/giantvm_config.h`**:
    *   æ·»åŠ  `#ifndef GIANTVM_CONFIG_H`ã€‚
    *   `#define GVM_SLAVE_BITS 17` (131072 Nodes).
    *   `#define GVM_GW_BITS 13` (8192 Nodes/GW).
    *   `#define GVM_MAX_SLAVES (1UL << GVM_SLAVE_BITS)`.
    *   `#define GVM_MAX_GATEWAYS (GVM_MAX_SLAVES >> GVM_GW_BITS)`.
*   **`common_include/giantvm_protocol.h`**:
    *   `struct gvm_header` (packed):
        *   `uint32_t magic;`
        *   `uint16_t msg_type;`
        *   `uint32_t slave_id;` (32-bit ID)
        *   `uint64_t req_id;`
        *   `uint32_t payload_len;`
        *   `uint8_t  is_frag;`
*   **`common_include/platform_defs.h`**:
    *   `#ifdef __KERNEL__`: include `<linux/vmalloc.h>`, `<linux/slab.h>`, `<linux/types.h>`.
    *   `#else`: include `<stdlib.h>`, `<stdint.h>`, `<string.h>`, `<stdio.h>`.

## Step 2: é©±åŠ¨æ¥å£ä¸ Master æ ¸å¿ƒ (Driver & Core)
**ç›®æ ‡**ï¼šå®ç°å®‰å…¨çš„å†…å­˜ç®¡ç†ä¸å¥å£®çš„å†…æ ¸åç«¯ã€‚

*   **`master_core/unified_driver.h`**:
    *   **å¿…é¡»æŒ‰æ­¤å®šä¹‰**ï¼š
    ```c
    struct dsm_driver_ops {
        // å¤§å†…å­˜ç®¡ç†
        void* (*alloc_large_table)(size_t size);
        void  (*free_large_table)(void *ptr);
        // ç½‘ç»œåŒ…ç®¡ç† (Slab)
        void* (*alloc_packet)(size_t size, int atomic);
        void  (*free_packet)(void *ptr);  // [å·²è¡¥å…¨]
        // ç½‘ç»œ I/O
        int   (*send_packet)(void *data, int len, uint32_t target_id);
        // è°ƒè¯•ä¸çŠ¶æ€
        void  (*log)(const char *fmt, ...);
        int   (*is_atomic_context)(void);
        void  (*touch_watchdog)(void);
    };
    ```
*   **`master_core/kernel_backend.c`**:
    *   `MODULE_LICENSE("GPL");`
    *   **Impl `alloc_large_table`**: `return vzalloc(size);` (Warning: Check process context).
    *   **Impl `alloc_packet`**: `kmem_cache_alloc`.
    *   **Impl `send_packet`**:
        *   `if (in_atomic() || irqs_disabled())`:
            *   Loop: `udp_poll_send` + `udelay(10)` + `touch_nmi_watchdog()`.
        *   `else`: `kernel_sendmsg`.
*   **`master_core/logic_core.c`**:
    *   **Global**: `static struct node_status *node_table = NULL;`
    *   **Init**:
        *   `node_table = ops->alloc_large_table(...)`.
        *   **CRITICAL**: `if (!node_table) { ops->log("FATAL: OOM in logic_init"); return -1; }`
        *   `ops->log("Logic Init: Allocated table for %u nodes", GVM_MAX_SLAVES);`
    *   **Sched**: `(vcpu < 4) ? LOCAL : REMOTE`.

## Step 3: QEMU é€‚é…å±‚ (QEMU 5.2.0 Frontend)
**ç›®æ ‡**ï¼šé€‚é… QEMU 5.2.0 åŠ é€Ÿå™¨æ¶æ„ã€‚

*   **`qemu_patch/accel/giantvm/giantvm-all.c`**:
    *   ä½¿ç”¨ `type_init` å®æ³¨å†Œ `TYPE_GIANTVM_ACCEL`ã€‚
    *   å®ç° `init_machine`: æ‰“å¼€ Master è®¾å¤‡æ–‡ä»¶ (`/dev/giantvm`)ã€‚
*   **`qemu_patch/accel/giantvm/giantvm-cpu.c`**:
    *   æ‹¦æˆª `cpu_exec`ã€‚
    *   æ„é€  `gvm_vcpu_context`ï¼Œè°ƒç”¨ Master Coreã€‚
*   **`qemu_patch/hw/giantvm/giantvm_mem.c`**:
    *   å®šä¹‰ `MemoryRegionOps`ï¼Œå°†è¯»å†™é‡å®šå‘åˆ° GiantVM Backendã€‚

## Step 4: ä¼˜åŒ–çš„ç½‘å…³æœåŠ¡ (Gateway Optimized)
**ç›®æ ‡**ï¼šå®ç°ä½å†…å­˜å ç”¨çš„ç›²èšåˆã€‚

*   **`gateway_service/aggregator.c`**:
    *   Include `giantvm_config.h`.
    *   **Data Structure**: `struct slave_buffer **buffers;` (Pointer Array).
    *   **Init**:
        *   `buffers = calloc(GVM_MAX_SLAVES, sizeof(void*));`
        *   Check NULL.
    *   **Process Packet**:
        *   `if (buffers[target_id] == NULL)`: `buffers[target_id] = malloc(MTU);`
        *   æ‰§è¡Œ `memcpy` èšåˆé€»è¾‘ã€‚
        *   æ£€æŸ¥æ˜¯å¦æ»¡åŒ…æˆ–è¶…æ—¶ï¼Œè‹¥æ˜¯åˆ™å‘é€ã€‚

## Step 5: ä»èŠ‚ç‚¹ä¸éƒ¨ç½² (Slave & Deploy)
**ç›®æ ‡**ï¼šå®ç°è®¡ç®—æ‰§è¡Œä¸è‡ªåŠ¨åŒ–éƒ¨ç½²ã€‚

*   **`slave_daemon/net_uring.c`**:
    *   å®ç°æºç«¯åˆ†ç‰‡ (Source Fragmentation)ï¼Œé€‚é… MTU 1280ã€‚
*   **`deploy/master/setup_host.sh`**:
    *   `sysctl -w vm.nr_hugepages=10240` (å¼€å¯å¤§é¡µï¼Œé™ä½é¡µè¡¨å¼€é”€).
*   **`guest_tools/win_memory_hint.cpp`**:
    *   ä½¿ç”¨ `VirtualAllocExNuma` ç”³è¯·å†…å­˜ï¼Œä¼ªé€  NUMA æ‹“æ‰‘ã€‚

---

**æ‰§è¡ŒæŒ‡ä»¤ (Command)**:

**è¯·å…ˆæ‰§è¡Œ Step 1 (åŸºç¡€è®¾æ–½) å’Œ Step 2 (æ ¸å¿ƒä¸æ¥å£) çš„ä»£ç ç”Ÿæˆã€‚**
**ç‰¹åˆ«æ³¨æ„**ï¼š
1.  ç¡®ä¿ `kernel_backend.c` ä¸­åŒ…å«äº†å®Œæ•´çš„æ­»é”é˜²æŠ¤é€»è¾‘ï¼ˆåŸå­æ£€æŸ¥ + çœ‹é—¨ç‹—ï¼‰ã€‚
2.  ç¡®ä¿ `dsm_driver_ops` å®šä¹‰ä¸­åŒ…å«äº† `free_packet`ï¼Œä¸”åœ¨é€»è¾‘å±‚æ­£ç¡®è°ƒç”¨ã€‚
```

@@@@@

è¿™æ˜¯ä¸€ä»½**æœ€ç»ˆå®šç¨¿ã€å…¨é‡åˆå¹¶ã€å·¥ç¨‹çº§**çš„å®æ–½æ‰‹å†Œã€‚
å®ƒå°†æ‰€æœ‰ä¹‹å‰çš„è®¨è®ºï¼ˆåŒ…æ‹¬æ ˆæº¢å‡ºä¿®å¤ã€å¯åŠ¨é£æš´ä¿®å¤ã€ä¸‡èŠ‚ç‚¹æ‰©å±•ã€åŒæ¨¡åˆ‡æ¢ï¼‰æ•´åˆä¸ºä¸€ä»½å¯ç›´æ¥æ‰§è¡Œçš„æ–‡æ¡£ã€‚

---

**é€‚ç”¨ç‰ˆæœ¬ï¼š** GiantVM-KVM (Linux 5.x/4.x basis) & QEMU 4.x/5.x basis
**æ ¸å¿ƒç›®æ ‡ï¼š** æ”¯æŒ 10,240 èŠ‚ç‚¹é›†ç¾¤ï¼Œä¿®å¤æ‰€æœ‰å·²çŸ¥å´©æºƒç‚¹ï¼Œå®ç° Kernel/UFFD åŒæ¨¡è‡ªåŠ¨åˆ‡æ¢ã€‚

---

## 1. å†…æ ¸æ¨¡å—ä¿®æ”¹æ¸…å• (GiantVM-KVM)
*å·¥ä½œç›®å½•ï¼š`giantvm-kvm/` æˆ– `kernel/`*

### 1.1 å¤´æ–‡ä»¶æ‰©å®¹ä¸ç»“æ„ä½“é‡æ„
**æ–‡ä»¶ï¼š** `kvm_host.h`

**ã€æ“ä½œã€‘** æ‰¾åˆ° `DSM_MAX_INSTANCES` å’Œ `copyset_t` çš„å®šä¹‰ã€‚

**ã€ä¿®æ”¹å‰ã€‘** (ç¤ºä¾‹)
```c
#define DSM_MAX_INSTANCES 64
typedef unsigned long copyset_t[...]; // å¯èƒ½æ˜¯æ•°ç»„å®šä¹‰
```

**ã€ä¿®æ”¹åã€‘** (å¼ºåˆ¶æ‰©å®¹å¹¶å°è£…ä¸ºç»“æ„ä½“ï¼Œé˜²æ­¢å‚æ•°ä¼ é€’æ—¶é€€åŒ–ä¸ºæŒ‡é’ˆ)
```c
#ifndef __KVM_HOST_H_FRONTIER_EXTENSION
#define __KVM_HOST_H_FRONTIER_EXTENSION

/* [Frontier] 1. æ‰©å®¹ä¸å¤´æ–‡ä»¶ä¾èµ– */
#define DSM_MAX_INSTANCES 10240
#include <linux/bitmap.h>
#include <linux/slab.h>
#include <linux/types.h>

/* [Frontier] 2. æ–°ç‰ˆ Copyset */
typedef struct {
    unsigned long bits[BITS_TO_LONGS(DSM_MAX_INSTANCES)];
} copyset_t;

/* [Frontier] 3. æ¬è¿æšä¸¾å®šä¹‰ */
enum kvm_dsm_request_type {
	DSM_REQ_INVALIDATE,
	DSM_REQ_READ,
	DSM_REQ_WRITE,
};

/* 
 * [Frontier Critical Fix] 
 * 1. åŠ ä¸Š __attribute__((packed)) é˜²æ­¢ç¼–è¯‘å™¨å¡«å……å­—èŠ‚å¯¼è‡´åè®®é”™ä½ã€‚
 * 2. version å‡çº§ä¸º uint32_t é˜²æ­¢é«˜é¢‘è¯»å†™å›ç»•ã€‚
 */

/* [Frontier] 4. æ¬è¿å¹¶å¼ºåŒ– Request ç»“æ„ä½“ */
struct dsm_request {
	unsigned char requester;
	unsigned char msg_sender;
	gfn_t gfn;
	unsigned char req_type;
	bool is_smm;
	uint32_t version;     /* Fix: ä» uint16_t å‡çº§ä¸º uint32_t */
} __attribute__((packed)); /* Fix: å¼ºåˆ¶å¯¹é½ */

/* [Frontier] 5. æ¬è¿å¹¶å¼ºåŒ– Response ç»“æ„ä½“ */
struct dsm_response {
	copyset_t inv_copyset;
	uint32_t version;     /* Fix: ä» uint16_t å‡çº§ä¸º uint32_t */
} __attribute__((packed)); /* Fix: å¼ºåˆ¶å¯¹é½ */

/* [Frontier] 6. å£°æ˜å…¨å±€ç¼“å­˜æ± å˜é‡ (ä¾› ivy.c ä½¿ç”¨) */
extern struct kmem_cache *dsm_resp_cache;

#endif /* __KVM_HOST_H_FRONTIER_EXTENSION */

/* 
 * /* [Frontier] 7.(å¯èƒ½å’Œä¸Šé¢é‚£å‡ æ¡ä¸åœ¨åŒä¸€ä¸ª kvm_host.h æ–‡ä»¶é‡Œ)
 * å¿…é¡»ä¸ kvm_host.h ä¸­çš„ copyset_t å®šä¹‰ä¿æŒä¸€è‡´ã€‚
 * ä¹‹å‰çš„ uint16_t åªèƒ½å­˜ 16 ä¸ªèŠ‚ç‚¹ï¼Œç°åœ¨éœ€è¦å­˜ 10240 ä¸ªèŠ‚ç‚¹ã€‚
 */

typedef struct tx_add {
#ifdef IVY_KVM_DSM
    /* 
     * [ä¿®æ”¹] ç›´æ¥åµŒå…¥ç»“æ„ä½“ 
     * è¿™é‡Œä¼šå ç”¨çº¦ 1280 å­—èŠ‚ï¼Œç½‘ç»œå±‚å¿…é¡»æ”¯æŒå‘é€è¿™ä¹ˆå¤§çš„åŒ…å¤´ 
     */
    copyset_t inv_copyset;
    
    /* [ä¿®æ”¹] å‡çº§ä¸º 32 ä½ä»¥åŒ¹é… kvm_host.h çš„å®šä¹‰ */
    uint32_t version;
    
#elif defined(TARDIS_KVM_DSM)
    /* 
     * Tardis æ¨¡å¼å¦‚æœä¸ç”¨ copysetï¼Œä¿ç•™ Padding å³å¯ã€‚
     * ä½†å»ºè®®æ£€æŸ¥ Tardis é€»è¾‘æ˜¯å¦ä¹Ÿå—å½±å“ã€‚
     */
    uint16_t padding;
#endif

    /*
     * (Hopefully) unique transcation id
     */
    uint16_t txid;

} __attribute__((packed)) tx_add_t; /* [å¿…é¡»] å¼ºåˆ¶ç´§å‡‘å¯¹é½ */
```

---

### 1.2. æ ¸å¿ƒåè®®é€»è¾‘ (æ ˆæº¢å‡ºä¿®å¤ + Jitter + Cache)
**æ–‡ä»¶ï¼š** `ivy.c`

**ã€ä¿®æ”¹ç›®æ ‡ã€‘**
1.  å¼•å…¥éšæœºå»¶è¿Ÿ (`inject_jitter`) é˜²æ­¢ TCP æ‹¥å¡ã€‚
2.  å°†å¤§ç»“æ„ä½“ (`struct dsm_response`) æ”¹ä¸ºä» Slab Cache åŠ¨æ€åˆ†é…ã€‚
3.  ä¿®å¤ Copyset æŒ‡é’ˆæ“ä½œã€‚

**ã€ä»£ç å¯¹æ¯”ã€‘**

#### A. è¾…åŠ©å‡½æ•°ä¸å¤´æ–‡ä»¶

**[ä¿®æ”¹å / Modified]** (ç›´æ¥æ·»åŠ åœ¨æ–‡ä»¶å¤´éƒ¨)
```c
/* ivy.c å¤´éƒ¨ */

/* ... includes ... */

/* 
 * [åˆ é™¤/æ³¨é‡Š] åŸæ¥çš„ç»“æ„ä½“å®šä¹‰ï¼Œå› ä¸ºå·²ç»ç§»åˆ° kvm_host.h äº†
 * enum kvm_dsm_request_type { ... };
 * struct dsm_request { ... };
 * struct dsm_response { ... };
 */

/* ç¡®ä¿åŒ…å«ä¿®æ”¹åçš„å¤´æ–‡ä»¶ */
#include "kvm_host.h" 
#include <linux/random.h>
#include <linux/delay.h>
#include <linux/nmi.h>
#include <linux/sched.h>
#include <linux/watchdog.h>
#include <linux/percpu.h>
#include <linux/preempt.h>
#include <linux/module.h>

/* 
 * [åˆ é™¤] enum kvm_dsm_request_type ... (å·²ç§»è‡³ kvm_host.h)
 * [åˆ é™¤] struct dsm_request ... (å·²ç§»è‡³ kvm_host.h)
 * [åˆ é™¤] struct dsm_response ... (å·²ç§»è‡³ kvm_host.h)
 */

/* å®šä¹‰å¯é…ç½®çš„åŸå­æ“ä½œè¶…æ—¶ï¼ˆå•ä½ï¼šæ¯«ç§’ï¼‰ */
static int atomic_timeout_ms = 1000; /* é»˜è®¤1ç§’ï¼Œä¿æŒå®‰å…¨åŸºçº¿ */
module_param(atomic_timeout_ms, int, 0644);
MODULE_PARM_DESC(atomic_timeout_ms, "Timeout in milliseconds for atomic network operations before triggering guest fault. (Default: 1000)");

/* [æ·»åŠ ] å®šä¹‰ Per-CPU å‘é€ç¼“å†²åŒºï¼Œä¸“ä¾›åŸå­ä¸Šä¸‹æ–‡ä½¿ç”¨ï¼Œé˜²æ­¢ OOM */
static DEFINE_PER_CPU(tx_add_t, atomic_tx_buffer);
static DEFINE_PER_CPU(int, tx_buffer_busy);

/* [ä¿ç•™] è¿™ä¸ªæ˜¯æœ¬åœ°è°ƒè¯•ç”¨çš„æè¿°ç¬¦ï¼Œä¸ç”¨ç§» */
static char* req_desc[3] = {"INV", "READ", "WRITE"};

/* 
 * [ä¿®æ”¹] dsm_get_copyset
 * å˜åŒ–ï¼šç°åœ¨ copyset æ˜¯ç»“æ„ä½“ï¼Œæˆ‘ä»¬éœ€è¦è¿”å›å®ƒçš„åœ°å€ (&)ï¼Œ
 * å¦åˆ™è¿”å›çš„æ˜¯æ•´ä¸ªå·¨å¤§çš„ç»“æ„ä½“å‰¯æœ¬ã€‚
 */
static inline copyset_t *dsm_get_copyset(
		struct kvm_dsm_memory_slot *slot, hfn_t vfn)
{
    /* æ·»åŠ  & å–åœ°å€ç¬¦ */
	return &slot->vfn_dsm_state[vfn - slot->base_vfn].copyset;
}

/* [Frontier] å¾®ç§’çº§æŠ–åŠ¨ï¼Œæ‰“æ•£ä¸‡èŠ‚ç‚¹å¹¶å‘è¯·æ±‚ */
/* å®šä¹‰ä¸€ä¸ªæ¨¡å—å‚æ•°ï¼Œå…è®¸è¿è¡Œæ—¶ä¿®æ”¹ */
static int enable_jitter = 1;
module_param(enable_jitter, int, 0644);

/* ä¿®æ”¹ helper å‡½æ•°ï¼Œå¢åŠ å®‰å…¨æ£€æŸ¥ */
static inline void inject_jitter(void) {
    if (!enable_jitter) return;
    
    /* [å…³é”®ä¿®æ­£] å¦‚æœå¤„äºåŸå­ä¸Šä¸‹æ–‡(ä¸­æ–­/è‡ªæ—‹é”)ï¼Œç»å¯¹ä¸èƒ½ç©ºè½¬ç­‰å¾…ï¼
     * å¦åˆ™ä¼šå¯¼è‡´ NMI Watchdog è®¤ä¸º CPU æ­»é”ï¼Œæˆ–è€…é˜»ç¢å…¶ä»–æ ¸è·å–é”ã€‚
     */
    if (in_atomic() || irqs_disabled()) {
        return; 
    }

    /* åªæœ‰åœ¨æ™®é€šè¿›ç¨‹ä¸Šä¸‹æ–‡ï¼ˆå¯ä»¥è¢«æŠ¢å /è°ƒåº¦ï¼‰æ‰è¿›è¡ŒæŠ–åŠ¨ */
    unsigned int delay = prandom_u32() % 10000;
    ndelay(delay);
}

/* [ä¿®æ”¹] é€‚é…ç»“æ„ä½“ */
static inline void dsm_add_to_copyset(struct kvm_dsm_memory_slot *slot, hfn_t vfn, int id)
{
    copyset_t *cs = dsm_get_copyset(slot, vfn);
    
    /* [Frontier æ–°å¢] ç†”æ–­æœºåˆ¶ (å¯èƒ½æœ‰é€»è¾‘é”™è¯¯ï¼Œåˆ æ‰)
     * å¦‚æœä¸€ä¸ªé¡µé¢å·²ç»è¢«è¶…è¿‡ 128 ä¸ªèŠ‚ç‚¹å…±äº«ï¼Œæ‹’ç»æ–°çš„èŠ‚ç‚¹åŠ å…¥å…±äº«é›†ã€‚
     * æ–°èŠ‚ç‚¹å°†è¢«è¿«å‘ owner å‘èµ·å•æ’­è¯»å–ï¼Œè€Œä¸æ˜¯åŠ å…¥ copysetã€‚
     * ç›®çš„ï¼šé˜²æ­¢åç»­å‘ç”Ÿ Write æ—¶ï¼ŒOwner éœ€è¦å‘é€ 10000 ä¸ª Invalidation åŒ…å¯¼è‡´ç³»ç»Ÿå¡æ­»ã€‚*/
     
    if (bitmap_weight(cs->bits, DSM_MAX_INSTANCES) > 128) {
        return;
    } 

    set_bit(id, cs->bits);
}

/* [ä¿®æ”¹] é€‚é…ç»“æ„ä½“ */
static inline void dsm_clear_copyset(struct kvm_dsm_memory_slot *slot, hfn_t vfn)
{
    bitmap_zero(dsm_get_copyset(slot, vfn)->bits, DSM_MAX_INSTANCES);
}

/* 
 * kvm_dsm_fetch - Modified for "Watchdog-Aware Persistence"
 * ä¿®å¤ï¼šæ··åˆå†…å­˜åˆ†é…ç­–ç•¥ + åŸå­ä¸Šä¸‹æ–‡æ­»é” + è„‘è£‚é˜²æŠ¤
 */
/*
 * kvm_dsm_fetch - Modified for "Tolerant Asynchronous Operations" (æ–¹æ¡ˆA)
 * æœ€ç»ˆä¿®æ­£ç‰ˆï¼š
 * 1. ä½¿ç”¨å¯ç”±æ¨¡å—å‚æ•° `atomic_timeout_ms` é…ç½®çš„è¶…æ—¶é˜ˆå€¼ã€‚
 * 2. åœ¨åŸå­ç­‰å¾…å¾ªç¯ä¸­ï¼Œä½¿ç”¨ udelay(10) + touch_watchdog() ç­–ç•¥ï¼Œ
 *    ä»¥åœ¨ä¿è¯ä¸»æœºå®‰å…¨çš„åŒæ—¶ï¼Œä¸ºç½‘ç»œåè®®æ ˆäº‰å–å¤„ç†æ—¶é—´ã€‚
 * 3. è¶…æ—¶åä¾æ—§è¿”å› -EIOï¼Œä»¥å¼ºåˆ¶æ‰§è¡Œå®‰å…¨çš„ VM ç†”æ–­æœºåˆ¶ã€‚
 * 4. ä¿ç•™æ‰€æœ‰åŸæœ‰ä¼˜åŒ–ï¼šæ··åˆå†…å­˜åˆ†é…ã€Jitter ç­‰ã€‚
 */
static int kvm_dsm_fetch(struct kvm *kvm, uint16_t dest_id, bool from_server,
		const struct dsm_request *req, void *data, struct dsm_response *resp)
{
	kconnection_t **conn_sock;
	int ret;
    tx_add_t *tx_add;
	int retry_cnt = 0;
    int send_flags = 0;
    int recv_flags = 0;
    bool is_atomic = false;
    bool use_percpu_buffer = false;
    
    u64 start_time_ns = 0;

    /* 1. å†…å­˜åˆ†é…ç­–ç•¥ (æ··åˆæ¨¡å¼) - ä¿æŒä¸å˜ */
    if (in_atomic() || irqs_disabled()) {
        int *busy = this_cpu_ptr(&tx_buffer_busy);
        if (*busy) return -EBUSY; /* é‡å…¥ä¿æŠ¤ */

        *busy = 1;
        is_atomic = true;
        send_flags = MSG_DONTWAIT;
        recv_flags = MSG_DONTWAIT;
        
        tx_add = this_cpu_ptr(&atomic_tx_buffer);
        memset(tx_add, 0, sizeof(tx_add_t));
        use_percpu_buffer = true;
    } else {
        is_atomic = false;
        send_flags = 0;
        recv_flags = SOCK_NONBLOCK;
        
        tx_add = kzalloc(sizeof(tx_add_t), GFP_KERNEL);
        if (!tx_add) {
            printk(KERN_ERR "kvm-dsm: Critical memory exhaustion in fetch\n");
            return -ENOMEM;
        }
        use_percpu_buffer = false;
    }

	tx_add->txid = generate_txid(kvm, dest_id);

    /* 2. æ³¨å…¥æŠ–åŠ¨ (å¦‚æœåœ¨éåŸå­ä¸Šä¸‹æ–‡) - ä¿æŒä¸å˜ */
    inject_jitter();

	if (kvm->arch.dsm_stopped) {
        ret = -EINVAL;
        goto done_free;
    }
    
    /* è¿æ¥é€»è¾‘ - ä¿æŒä¸å˜ */
	if (!from_server)
		conn_sock = &kvm->arch.dsm_conn_socks[dest_id];
	else
		conn_sock = &kvm->arch.dsm_conn_socks[DSM_MAX_INSTANCES + dest_id];

	if (*conn_sock == NULL) {
        if (is_atomic) {
            ret = -ENOTCONN;
            goto done_free;
        }
		mutex_lock(&kvm->arch.conn_init_lock);
		if (*conn_sock == NULL) {
			ret = kvm_dsm_connect(kvm, dest_id, conn_sock);
			if (ret < 0) {
				mutex_unlock(&kvm->arch.conn_init_lock);
                goto done_free;
			}
		}
		mutex_unlock(&kvm->arch.conn_init_lock);
	}

	dsm_debug_v("kvm[%d] sent request[0x%x] to kvm[%d] req_type[%s] gfn[%llu,%d]",
			kvm->arch.dsm_id, tx_add->txid, dest_id, req_desc[req->req_type],
			req->gfn, req->is_smm);

retry_send:
    ret = network_ops.send(*conn_sock, (const char *)req, sizeof(struct dsm_request), send_flags, tx_add);

    /* [æ ¸å¿ƒä¿®æ­£][æ–¹æ¡ˆA] é’ˆå¯¹â€œä¸å¤Ÿå¥½â€ç½‘ç»œçš„å®½å®¹ç­‰å¾…ç­–ç•¥ */
    if (ret == -EAGAIN && is_atomic) {
        if (unlikely(start_time_ns == 0)) start_time_ns = local_clock();
        
        /* ä½¿ç”¨æ¨¡å—å‚æ•°æ¥å†³å®šè¶…æ—¶æ—¶é—´ */
        if (unlikely((local_clock() - start_time_ns) > (u64)atomic_timeout_ms * 1000 * 1000)) {
            printk(KERN_EMERG "GiantVM: [FATAL] Atomic send STUCK > %dms. Halting VM operation.\n", atomic_timeout_ms);
            ret = -EIO; /* è¿”å›è‡´å‘½I/Oé”™è¯¯ï¼Œä¸Šå±‚å¿…é¡»å¤„ç† */
            goto done_free;
        }

        /* å…³é”®ï¼šå–‚ç‹—ï¼Œé˜²æ­¢ç‰©ç†æœºå›  NMI watchdog é‡å¯ */
        touch_nmi_watchdog();
        touch_softlockup_watchdog();
        
        /* å…³é”®ï¼šä½¿ç”¨ udelay(10) ä»£æ›¿ cpu_relax()ï¼Œä¸ºç½‘ç»œå¤„ç†äº‰å–æ—¶é—´ */
        udelay(10);
        
        goto retry_send;
    }
    
	if (ret < 0) goto done_free;

    /* é‡ç½®è®¡æ—¶å™¨ä¾›æ¥æ”¶ä½¿ç”¨ */
	retry_cnt = 0;
    start_time_ns = 0;
    
    /* 4. æ¥æ”¶é€»è¾‘ (åŒæ ·åº”ç”¨æ–¹æ¡ˆAçš„ç­–ç•¥) */
	if (req->req_type == DSM_REQ_INVALIDATE) {
retry_recv_inv:
        ret = network_ops.receive(*conn_sock, data, recv_flags, tx_add);
        if (ret == -EAGAIN && is_atomic) {
            if (unlikely(start_time_ns == 0)) start_time_ns = local_clock();
            
            if (unlikely((local_clock() - start_time_ns) > (u64)atomic_timeout_ms * 1000 * 1000)) {
                printk(KERN_EMERG "GiantVM: [FATAL] Atomic recv_inv STUCK > %dms.\n", atomic_timeout_ms);
                ret = -EIO;
                goto done_free;
            }

            touch_nmi_watchdog();
            touch_softlockup_watchdog();
            udelay(10);
            goto retry_recv_inv;
        }
	} else {
        /* æ™®é€šè¯·æ±‚æ¥æ”¶ (Read/Write response) */
retry:
		ret = network_ops.receive(*conn_sock, data, recv_flags, tx_add);
		if (ret == -EAGAIN) {
            /* åŸå­ä¸Šä¸‹æ–‡çš„è¶…æ—¶é€»è¾‘ */
            if (is_atomic) {
                if (unlikely(start_time_ns == 0)) start_time_ns = local_clock();
                
                if (unlikely((local_clock() - start_time_ns) > (u64)atomic_timeout_ms * 1000 * 1000)) {
                     printk(KERN_EMERG "GiantVM: [FATAL] Atomic recv STUCK > %dms. Killing VM.\n", atomic_timeout_ms);
                     ret = -EIO;
                     goto done_free;
                }
                touch_nmi_watchdog();
                touch_softlockup_watchdog();
                udelay(10);
                goto retry;
            }

            /* æ™®é€šè¿›ç¨‹ä¸Šä¸‹æ–‡çš„è¶…æ—¶é€»è¾‘ (ä¿ç•™åŸç‰ˆé€»è¾‘) */
			retry_cnt++;
			if (retry_cnt > 100000) {
				printk_ratelimited("%s: Waiting long for gfn %llu from kvm %d\n",
						__func__, req->gfn, dest_id);
				retry_cnt = 0;
                cond_resched(); /* è®©å‡º CPU */
			}
			goto retry;
		}
		resp->inv_copyset = tx_add->inv_copyset;
		resp->version = tx_add->version;
	}
	if (ret < 0) goto done_free;

done_free:
    if (use_percpu_buffer) {
        *this_cpu_ptr(&tx_buffer_busy) = 0; /* é‡Šæ”¾ Per-CPU é” */
    } else {
        kfree(tx_add);
    }
	return ret;
}
```

#### B. å¤±æ•ˆå¹¿æ’­é€»è¾‘ (ä¿®å¤éå† Bug)
**ã€æ›¿æ¢è¯´æ˜ã€‘** æ‰¾åˆ° `kvm_dsm_invalidate` å‡½æ•°ï¼Œå…¨é‡æ›¿æ¢ã€‚

```c
/*
 * kvm_dsm_invalidate - issued by owner of a page to invalidate all of its copies
 * ä¿®å¤ï¼šä¸‡èŠ‚ç‚¹å¾ªç¯çœ‹é—¨ç‹— + é”™è¯¯ä¼ æ’­
 */
static int kvm_dsm_invalidate(struct kvm *kvm, gfn_t gfn, bool is_smm,
		struct kvm_dsm_memory_slot *slot, hfn_t vfn, copyset_t *cpyset, int req_id)
{
	int holder;
	int ret = 0;
	char r = 1; /* Dummy buffer for ACK */
	copyset_t *copyset;
	struct dsm_response resp; /* Placeholder */
    
    int loop_cnt = 0;

	copyset = cpyset ? cpyset : dsm_get_copyset(slot, vfn);

	for_each_set_bit(holder, copyset->bits, DSM_MAX_INSTANCES) {
		
        struct dsm_request req = {
			.req_type = DSM_REQ_INVALIDATE,
			.requester = kvm->arch.dsm_id,
			.msg_sender = kvm->arch.dsm_id,
			.gfn = gfn,
			.is_smm = is_smm,
			.version = dsm_get_version(slot, vfn),
		};
        
		if (kvm->arch.dsm_id == holder)
			continue;
        
		BUG_ON(holder >= kvm->arch.cluster_iplist_len);

		ret = kvm_dsm_fetch(kvm, holder, false, &req, &r, &resp);
		
        if (ret < 0) {
            if (ret == -EIO) {
                printk(KERN_EMERG "GiantVM: Invalidation aborted due to network failure. Halting guest.\n");
                return -EIO;
            }
			return ret;
        }

        if (++loop_cnt % 64 == 0) { 
            touch_nmi_watchdog();        
            touch_softlockup_watchdog(); 
            
            if (!in_atomic() && !irqs_disabled()) {
                cond_resched();
            } else {
                cpu_relax();
            }
        }
	}

	return 0;
}
```

#### C. å†™è¯·æ±‚å¤„ç† (dsm_handle_write_req)

**[åŸä»£ç  / Original]** (é€»è¾‘æ¦‚è¦)
```c
static int dsm_handle_write_req(...) {
    struct dsm_response resp; // åœ¨æ ˆä¸Šåˆ†é…ï¼Œå¯¼è‡´æ ˆæº¢å‡º
    /* ... é€»è¾‘å¤„ç† ... */
    tx_add->inv_copyset = resp.inv_copyset;
    /* ... */
}
```

**[ä¿®æ”¹å / Modified]**
```c
static int dsm_handle_write_req(struct kvm *kvm, kconnection_t *conn_sock,
		struct kvm_memory_slot *memslot, struct kvm_dsm_memory_slot *slot,
		const struct dsm_request *req, bool *retry, hfn_t vfn, char *page,
		tx_add_t *tx_add)
{
    int ret = 0, length = 0;
    int owner = -1;
    bool is_owner = false;
    struct dsm_response *resp;
    resp = kmem_cache_zalloc(dsm_resp_cache, GFP_ATOMIC);
    if (!resp) return -ENOMEM;
    if (dsm_is_pinned_read(slot, vfn) && !kvm->arch.dsm_stopped) {
        *retry = true;
        goto out_free; 
    }
    if ((is_owner = dsm_is_owner(slot, vfn))) {
        BUG_ON(dsm_get_prob_owner(slot, vfn) != kvm->arch.dsm_id);
        dsm_change_state(slot, vfn, DSM_INVALID);
        kvm_dsm_apply_access_right(kvm, slot, vfn, DSM_INVALID);
        memcpy(&resp->inv_copyset, dsm_get_copyset(slot, vfn), sizeof(copyset_t));
        resp->version = dsm_get_version(slot, vfn);
        clear_bit(kvm->arch.dsm_id, resp->inv_copyset.bits);
        ret = kvm_read_guest_page_nonlocal(kvm, memslot, req->gfn, page, 0, PAGE_SIZE);
        if (ret < 0) goto out_free;
    }
    else if (dsm_is_initial(slot, vfn) && kvm->arch.dsm_id == 0) {
        bitmap_zero(resp->inv_copyset.bits, DSM_MAX_INSTANCES);
        resp->version = dsm_get_version(slot, vfn);
        ret = kvm_read_guest_page_nonlocal(kvm, memslot, req->gfn, page, 0, PAGE_SIZE);
        if (ret < 0) goto out_free;
        dsm_set_prob_owner(slot, vfn, req->msg_sender);
        dsm_change_state(slot, vfn, DSM_INVALID);
    }
    else {
        struct dsm_request new_req = { /* ... */ };
        owner = dsm_get_prob_owner(slot, vfn);
        ret = length = kvm_dsm_fetch(kvm, owner, true, &new_req, page, resp);
        if (ret == -EIO) {
            printk(KERN_EMERG "GiantVM: Write fetch failed (Network Dead). Halting.\n");
            goto out_free;
        }
        if (ret < 0) goto out_free;
        dsm_change_state(slot, vfn, DSM_INVALID);
        kvm_dsm_apply_access_right(kvm, slot, vfn, DSM_INVALID);
        dsm_set_prob_owner(slot, vfn, req->msg_sender);
        clear_bit(kvm->arch.dsm_id, resp->inv_copyset.bits);
    }
    if (is_owner) {
        length = dsm_encode_diff(slot, vfn, req->msg_sender, page, memslot, req->gfn, req->version);
    }
    tx_add->inv_copyset = resp->inv_copyset;
    tx_add->version = resp->version;
    if (ret >= 0) {
        ret = network_ops.send(conn_sock, page, length, 0, tx_add);
    }
out_free:
    kmem_cache_free(dsm_resp_cache, resp);
    return ret;
}
```

#### D. è¯»è¯·æ±‚å¤„ç† (dsm_handle_read_req)

**ã€æ“ä½œã€‘** æ‰“å¼€ `ivy.c`ï¼Œæ‰¾åˆ° `dsm_handle_read_req`ï¼Œç”¨ä¸‹é¢çš„ä»£ç **å…¨é‡æ›¿æ¢**ï¼š

```c
static int dsm_handle_read_req(struct kvm *kvm, kconnection_t *conn_sock,
		struct kvm_memory_slot *memslot, struct kvm_dsm_memory_slot *slot,
		const struct dsm_request *req, bool *retry, hfn_t vfn, char *page,
		tx_add_t *tx_add)
{
    int ret = 0, length = 0;
    int owner = -1;
    bool is_owner = false;
    struct dsm_response *resp;
    resp = kmem_cache_zalloc(dsm_resp_cache, GFP_ATOMIC);
    if (!resp) return -ENOMEM;
    resp->version = 0;
    if (dsm_is_pinned_read(slot, vfn) && !kvm->arch.dsm_stopped) {
        *retry = true;
        ret = 0;
        goto out_free;
    }
    if ((is_owner = dsm_is_owner(slot, vfn))) {
        BUG_ON(dsm_get_prob_owner(slot, vfn) != kvm->arch.dsm_id);
        dsm_set_prob_owner(slot, vfn, req->msg_sender);
        dsm_change_state(slot, vfn, DSM_SHARED);
        kvm_dsm_apply_access_right(kvm, slot, vfn, DSM_SHARED);
        ret = kvm_read_guest_page_nonlocal(kvm, memslot, req->gfn, page, 0, PAGE_SIZE);
        if (ret < 0) goto out_free;
        memcpy(&resp->inv_copyset, dsm_get_copyset(slot, vfn), sizeof(copyset_t));
        BUG_ON(!(test_bit(kvm->arch.dsm_id, resp->inv_copyset.bits)));
        resp->version = dsm_get_version(slot, vfn);
    }
    else if (dsm_is_initial(slot, vfn) && kvm->arch.dsm_id == 0) {
        ret = kvm_read_guest_page_nonlocal(kvm, memslot, req->gfn, page, 0, PAGE_SIZE);
        if (ret < 0) goto out_free;
        dsm_set_prob_owner(slot, vfn, req->msg_sender);
        dsm_change_state(slot, vfn, DSM_SHARED);
        dsm_add_to_copyset(slot, vfn, kvm->arch.dsm_id);
        memcpy(&resp->inv_copyset, dsm_get_copyset(slot, vfn), sizeof(copyset_t));
        resp->version = dsm_get_version(slot, vfn);
    }
    else {
        struct dsm_request new_req = { /* ... */ };
        owner = dsm_get_prob_owner(slot, vfn);
        ret = length = kvm_dsm_fetch(kvm, owner, true, &new_req, page, resp);
        if (ret == -EIO) {
            printk(KERN_EMERG "GiantVM: Read fetch failed (Network Dead). Halting.\n");
            goto out_free;
        }
        if (ret < 0) goto out_free;
        BUG_ON(dsm_is_readable(slot, vfn) && !(test_bit(kvm->arch.dsm_id, resp->inv_copyset.bits)));
        dsm_set_prob_owner(slot, vfn, req->msg_sender);
    }
    if (is_owner) {
        length = dsm_encode_diff(slot, vfn, req->msg_sender, page, memslot, req->gfn, req->version);
    }
    tx_add->inv_copyset = resp->inv_copyset;
    tx_add->version = resp->version;
    if (ret >= 0) {
	    ret = network_ops.send(conn_sock, page, length, 0, tx_add);
    }
out_free:
    kmem_cache_free(dsm_resp_cache, resp);
    return ret;
}
```

---

### 1.3 å†…å­˜æ§½æ‹·è´ä¿®æ­£ (dsm.c)
**æ–‡ä»¶ï¼š** `dsm.c`

**ã€æ“ä½œã€‘** æ‰¾åˆ° `kvm_dsm_add_memslot` å‡½æ•°ï¼Œæ›¿æ¢ç»“æ„ä½“æ‹·è´éƒ¨åˆ†ã€‚

```c
#ifdef IVY_KVM_DSM
    /* [ä¿®æ”¹] ä½¿ç”¨ bitmap_copy è¿›è¡Œæ‹·è´ */
    bitmap_copy(new_hvaslot->vfn_dsm_state[i + (vfn - new_hvaslot->base_vfn)].copyset.bits,
                hvaslot->vfn_dsm_state[i + (gfn - gfn_iter)].copyset.bits,
                DSM_MAX_INSTANCES);
#endif
```

### 1.4. æ¨¡å—ç”Ÿå‘½å‘¨æœŸç®¡ç† (Slab Cache åˆå§‹åŒ–)
**æ–‡ä»¶ï¼š** `kvm_main.c`

**ã€ä¿®æ”¹ç›®æ ‡ã€‘**
1.  å®šä¹‰å…¨å±€å˜é‡ `dsm_resp_cache`ã€‚
2.  åœ¨ `kvm_init` ä¸­åˆ›å»ºç¼“å­˜æ± ã€‚
3.  åœ¨ `kvm_exit` ä¸­é”€æ¯ç¼“å­˜æ± ã€‚

**ã€ä»£ç å¯¹æ¯”ã€‘**

#### A. å…¨å±€å˜é‡å®šä¹‰ (æ–‡ä»¶å¤´éƒ¨)

**[åŸä»£ç  / Original]**
*(æ— )*

**[ä¿®æ”¹å / Modified]**
```c
/* [Frontier] å®šä¹‰ DSM ä¸“ç”¨ç¼“å­˜æ±  */
struct kmem_cache *dsm_resp_cache;
EXPORT_SYMBOL_GPL(dsm_resp_cache);
```

#### B. åˆå§‹åŒ–å‡½æ•° (kvm_init)

**[åŸä»£ç  / Original]**
```c
	kvm_vcpu_cache = kmem_cache_create("kvm_vcpu", vcpu_size, vcpu_align,
					   SLAB_ACCOUNT, NULL);
	if (!kvm_vcpu_cache) {
		r = -ENOMEM;
		goto out_free_3;
	}

	r = kvm_async_pf_init();
	if (r)
		goto out_free;
```

**[ä¿®æ”¹å / Modified]**
```c
	kvm_vcpu_cache = kmem_cache_create("kvm_vcpu", vcpu_size, vcpu_align,
					   SLAB_ACCOUNT, NULL);
	if (!kvm_vcpu_cache) {
		r = -ENOMEM;
		goto out_free_3;
	}

	/* [Frontier] åˆå§‹åŒ– DSM Response ä¸“ç”¨ç¼“å­˜æ±  */
	/* è§£å†³ä¸‡èŠ‚ç‚¹é«˜é¢‘äº¤äº’ä¸‹çš„å†…æ ¸å†…å­˜ç¢ç‰‡é—®é¢˜ */
	dsm_resp_cache = kmem_cache_create("dsm_resp_cache", 
					   sizeof(struct dsm_response), 
					   0, SLAB_HWCACHE_ALIGN, NULL);
	if (!dsm_resp_cache) {
		r = -ENOMEM;
		goto out_free_vcpu_cache; /* è·³è½¬åˆ°ç‰¹å®šçš„é‡Šæ”¾ç‚¹ */
	}

	r = kvm_async_pf_init();
	if (r)
		goto out_free_dsm_cache; /* è·³è½¬åˆ°ç‰¹å®šçš„é‡Šæ”¾ç‚¹ */

    /* ... åç»­ä»£ç  ... */
    
    /* åœ¨å‡½æ•°æœ«å°¾æ·»åŠ æ–°çš„é”™è¯¯å¤„ç†æ ‡ç­¾ */
out_free_dsm_cache:
	kmem_cache_destroy(dsm_resp_cache);
out_free_vcpu_cache:
	kmem_cache_destroy(kvm_vcpu_cache);
    /* æ¥å…¥åŸæœ‰çš„ out_free_3 */
```

#### C. é€€å‡ºå‡½æ•° (kvm_exit)

**[åŸä»£ç  / Original]**
```c
void kvm_exit(void)
{
	debugfs_remove_recursive(kvm_debugfs_dir);
	misc_deregister(&kvm_dev);
	kmem_cache_destroy(kvm_vcpu_cache);
	kvm_async_pf_deinit();
    /* ... */
```

**[ä¿®æ”¹å / Modified]**
```c
void kvm_exit(void)
{
	debugfs_remove_recursive(kvm_debugfs_dir);
	misc_deregister(&kvm_dev);

	/* [Frontier] é”€æ¯ DSM ç¼“å­˜æ±  (LIFO åŸåˆ™ï¼Œå…ˆé”€æ¯ååˆ›å»ºçš„) */
	if (dsm_resp_cache)
		kmem_cache_destroy(dsm_resp_cache);

	kmem_cache_destroy(kvm_vcpu_cache);
	kvm_async_pf_deinit();
	unregister_syscore_ops(&kvm_syscore_ops);
	unregister_reboot_notifier(&kvm_reboot_notifier);
	cpuhp_remove_state_nocalls(CPUHP_AP_KVM_STARTING);
	on_each_cpu(hardware_disable_nolock, NULL, 1);
	kvm_arch_hardware_unsetup();
	kvm_arch_exit();
	kvm_irqfd_exit();
	free_cpumask_var(cpus_hardware_enabled);
	kvm_vfio_ops_exit();
}
EXPORT_SYMBOL_GPL(kvm_exit);
```

---

## 2. QEMU æºç ä¿®æ”¹æ¸…å• (QEMU-System)
*å·¥ä½œç›®å½•ï¼š`qemu/`*

### 2.1 ä¿®å¤ Select é™åˆ¶å´©æºƒ
**æ–‡ä»¶ï¼š** `hw/tpm/tpm_util.c`

**[åŸä»£ç  / Original]**
```c
    fd_set readfds;
    FD_ZERO(&readfds);
    FD_SET(fd, &readfds);
    n = select(fd + 1, &readfds, NULL, NULL, &tv);
```

**[ä¿®æ”¹å / Modified]**
```c
#include <poll.h> /* éœ€ç¡®ä¿åŒ…å« */

    /* [Frontier] ä½¿ç”¨ poll æ›¿ä»£ selectï¼Œé˜²æ­¢ fd > 1024 å´©æºƒ */
    struct pollfd pfd = { .fd = fd, .events = POLLIN };
    n = poll(&pfd, 1, 1000); /* 1000ms timeout */
```

### 2.2 UFFD åŒæ¨¡åç«¯å¼•æ“ (æ ¸å¿ƒæ–°å¢)

#### A. å¤´æ–‡ä»¶
**æ–°å¢æ–‡ä»¶ï¼š** `dsm_backend.h`

```c
#ifndef DSM_BACKEND_H
#define DSM_BACKEND_H
#include <stddef.h>
#include <stdint.h>
void dsm_universal_init(void);
void dsm_universal_register(void *ptr, size_t size);
#endif
```

#### B. å®ç°æ–‡ä»¶ (åŒ…å« Lazy Connect ä¸ ç»†ç²’åº¦é”)
**æ–‡ä»¶ï¼š** æ–°å¢ `dsm_backend.c`

**[å…¨é‡æ–°ä»£ç  / New File]**
```c
#include "qemu/osdep.h"
#include "qemu/thread.h"
#include "dsm_backend.h"
#include <time.h>
#include <sys/ioctl.h>
#include <unistd.h>
#include <linux/userfaultfd.h>
#include <sys/syscall.h>
#include <sys/socket.h>
#include <netinet/in.h>
#include <netinet/tcp.h>
#include <arpa/inet.h>
#include <sched.h>
#include <stdlib.h>
#include <signal.h>
#include <poll.h>

#define _GNU_SOURCE 
#include <endian.h>

#ifndef __NR_userfaultfd
#define __NR_userfaultfd 323
#endif

/* === é…ç½®åŒºåŸŸ === */
#define PREFETCH 32           // [å¾®è°ƒ] é¢„å–é¡µé¢æ•°é‡é™è‡³32ï¼Œåœ¨æ™®é€šç½‘ç»œä¸‹æ›´ç¨³å®š
#define PAGE_SIZE 4096
#define MAX_OPEN_SOCKETS 10240
#define WORKER_THREADS 128    // UFFD å¤„ç†çº¿ç¨‹æ•°

/* === å…¨å±€å˜é‡ (ä¿®æ”¹å) === */
int gvm_mode = 0;             // 0: Kernel Mode, 1: User Mode
int uffd_fd = -1;
int *global_sockets = NULL;
pthread_mutex_t *conn_locks = NULL;

// [ä¿®æ”¹] å°†ç¡¬ç¼–ç çš„IPåˆ—è¡¨æ›¿æ¢ä¸ºåŠ¨æ€å˜é‡
char **g_node_ips = NULL;     // å­˜å‚¨ä»é…ç½®æ–‡ä»¶è¯»å–çš„IPåœ°å€
int g_node_count = 0;         // å­˜å‚¨IPåœ°å€çš„æ•°é‡

/* 
 * [æ–°å¢] è§£æ cluster.conf æ–‡ä»¶çš„å‡½æ•°
 * ä½œç”¨: è¯»å–é…ç½®æ–‡ä»¶ï¼Œå¡«å…… g_node_ips å’Œ g_node_count
 */
static int parse_cluster_conf(const char *filename) {
    FILE *fp = fopen(filename, "r");
    if (!fp) {
        perror("[GiantVM] Failed to open cluster.conf");
        return -1;
    }

    char line[256];
    int count = 0;

    // ç¬¬ä¸€æ¬¡éå†ï¼šè®¡ç®—èŠ‚ç‚¹æ•°é‡
    while (fgets(line, sizeof(line), fp)) {
        if (line[0] != '#' && line[0] != '\n') {
            count++;
        }
    }

    if (count == 0) {
        fprintf(stderr, "[GiantVM] Error: cluster.conf is empty or contains no valid entries.\n");
        fclose(fp);
        return -1;
    }

    if (count == 0) {
        fprintf(stderr, "[GiantVM] Error: cluster.conf is empty or has 0 valid nodes.\n");
        fclose(fp); // åˆ«å¿˜äº†å…³é—­æ–‡ä»¶å¥æŸ„
        return -1;  // è¿”å›é”™è¯¯ï¼Œé˜»æ­¢åç»­é€»è¾‘æ‰§è¡Œ
    }

    g_node_count = count;
    g_node_ips = malloc(g_node_count * sizeof(char *));
    if (!g_node_ips) {
        perror("[GiantVM] Failed to allocate memory for IP list");
        fclose(fp);
        return -1;
    }

    // å›åˆ°æ–‡ä»¶å¼€å¤´
    rewind(fp);
    count = 0;
    char ip_buffer[20]; // ç”¨äºå­˜æ”¾IPåœ°å€çš„ä¸´æ—¶ç¼“å†²åŒº

    // ç¬¬äºŒæ¬¡éå†ï¼šè¯»å–IPåœ°å€
    while (fgets(line, sizeof(line), fp) && count < g_node_count) {
        if (line[0] == '#' || line[0] == '\n') {
            continue;
        }
        // è§£ææ ¼å¼ "ID IP PORT"ï¼Œæˆ‘ä»¬åªå…³å¿ƒIP
        if (sscanf(line, "%*d %19s %*d", ip_buffer) == 1) {
            g_node_ips[count] = strdup(ip_buffer);
            if (!g_node_ips[count]) {
                perror("[GiantVM] strdup failed for IP address");
                // ... æ­¤å¤„åº”æœ‰æ›´å®Œå–„çš„å†…å­˜é‡Šæ”¾é€»è¾‘ ...
                fclose(fp);
                return -1;
            }
            count++;
        }
    }

    fclose(fp);
    printf("[GiantVM] Loaded %d memory server IPs from %s\n", g_node_count, filename);
    return 0;
}


/* 
 * å»ºç«‹è¿æ¥åº•å±‚å‡½æ•° (æ— å˜åŒ–)
 */
static int connect_node_impl(const char *ip) {
    // ... æ­¤å‡½æ•°å†…å®¹ä¿æŒä¸å˜ ...
    int s = socket(AF_INET, SOCK_STREAM, 0);
    if (s < 0) return -1;
    struct linger sl = { .l_onoff = 1, .l_linger = 0 };
    setsockopt(s, SOL_SOCKET, SO_LINGER, &sl, sizeof(sl));
    int flag = 1;
    setsockopt(s, IPPROTO_TCP, TCP_NODELAY, (char*)&flag, sizeof(int));
    int keepalive = 1, keepidle = 5, keepintvl = 2, keepcnt = 3;
    setsockopt(s, SOL_SOCKET, SO_KEEPALIVE, &keepalive, sizeof(int));
    setsockopt(s, IPPROTO_TCP, TCP_KEEPIDLE, &keepidle, sizeof(int));
    setsockopt(s, IPPROTO_TCP, TCP_KEEPINTVL, &keepintvl, sizeof(int));
    setsockopt(s, IPPROTO_TCP, TCP_KEEPCNT, &keepcnt, sizeof(int));
    struct timeval timeout;
    timeout.tv_sec = 2;
    timeout.tv_usec = 0;
    setsockopt(s, SOL_SOCKET, SO_RCVTIMEO, (char *)&timeout, sizeof(timeout));
    setsockopt(s, SOL_SOCKET, SO_SNDTIMEO, (char *)&timeout, sizeof(timeout));
    struct sockaddr_in a;
    a.sin_family = AF_INET;
    a.sin_port = htons(9999);
    inet_pton(AF_INET, ip, &a.sin_addr);
    if (connect(s, (struct sockaddr*)&a, sizeof(a)) < 0) { 
        close(s); 
        return -1; 
    }
    return s;
}

/* 
 * [ä¿®æ”¹] è·å–è¿æ¥å¹¶é”å®š (ä½¿ç”¨ g_node_count å’Œ g_node_ips)
 */
static int get_or_connect_locked(int node_id) {
    if (node_id < 0 || node_id >= g_node_count) return -1;

    pthread_mutex_lock(&conn_locks[node_id]);

    if (global_sockets[node_id] != -1) {
        return global_sockets[node_id];
    }

    int s = connect_node_impl(g_node_ips[node_id]);
    if (s >= 0) {
        global_sockets[node_id] = s;
        return s;
    } else {
        pthread_mutex_unlock(&conn_locks[node_id]);
        return -1;
    }
}

/* 
 * è¾…åŠ©å‡½æ•°ï¼šå…³é—­è¿æ¥å¹¶æ¸…ç†çŠ¶æ€ (æ— å˜åŒ–)
 */
static void close_socket_locked(int node_id) {
    // ... æ­¤å‡½æ•°å†…å®¹ä¿æŒä¸å˜ ...
    int s = global_sockets[node_id];
    if (s != -1) {
        close(s);
        global_sockets[node_id] = -1;
    }
}

/* 
 * [ä¿®æ”¹] å·¥ä½œçº¿ç¨‹ (ä½¿ç”¨ g_node_count)
 */
void *dsm_worker(void *arg) {
    // ... æ­¤å‡½æ•°ä¸­é™¤äº† owner è®¡ç®—æ–¹å¼ï¼Œå…¶ä»–éƒ¨åˆ†ä¿æŒä¸å˜ ...
    const int BATCH_SIZE = 64;
    struct uffd_msg msgs[BATCH_SIZE];
    ssize_t nread;
    char *buf = malloc(PAGE_SIZE * PREFETCH);
    if (!buf) return NULL;
    struct sched_param p = { .sched_priority = 10 };
    pthread_setschedparam(pthread_self(), SCHED_RR, &p);

    while(1) {
        struct pollfd pfd = { .fd = uffd_fd, .events = POLLIN };
        int poll_ret = poll(&pfd, 1, 2000);
        if (poll_ret <= 0) continue;

        nread = read(uffd_fd, msgs, sizeof(struct uffd_msg) * BATCH_SIZE);
        if (nread <= 0) continue;
        int n_events = nread / sizeof(struct uffd_msg);

        for (int i = 0; i < n_events; i++) {
            struct uffd_msg *msg = &msgs[i];
            if (!(msg->event & UFFD_EVENT_PAGEFAULT)) continue;
            uint64_t addr = msg->arg.pagefault.address;
            uint64_t base = addr & ~(4095);

            // [ä¿®æ”¹] owner è®¡ç®—æ–¹å¼ï¼Œä½¿ç”¨ g_node_count
            int owner = (base / 4096) % g_node_count;
            
            int sock = get_or_connect_locked(owner);

            /* [ä½“éªŒä¼˜å…ˆçš„æƒè¡¡æ–¹æ¡ˆ] - è¿™éƒ¨åˆ†é€»è¾‘ä¿æŒä¸å˜ */
            if (sock < 0) {
                const int STALL_TIMEOUT_MS = 500;
                const int RETRY_INTERVAL_MS = 50;
                int total_wait_ms = 0;
                bool connected = false;

                fprintf(stderr, "[DSM] INFO: Node %d unreachable. Stalling for up to %dms on %lx...\n", 
                        owner, STALL_TIMEOUT_MS, base);

                while (total_wait_ms < STALL_TIMEOUT_MS) {
                    usleep(RETRY_INTERVAL_MS * 1000);
                    total_wait_ms += RETRY_INTERVAL_MS;
                    sock = get_or_connect_locked(owner);
                    if (sock >= 0) {
                        connected = true;
                        fprintf(stderr, "[DSM] INFO: Connection to node %d restored after %dms.\n", owner, total_wait_ms);
                        break;
                    }
                }

                if (!connected) {
                    fprintf(stderr, "[DSM] WARN: Node %d unreachable after %dms. Zero-filling %lx to unblock vCPU.\n", 
                            owner, STALL_TIMEOUT_MS, base);
                    struct uffdio_zeropage z = { .range = { .start = base, .len = 4096 }, .mode = 0 };
                    if (ioctl(uffd_fd, UFFDIO_ZEROPAGE, &z) < 0) {
                        if (errno == EEXIST) {
                             struct uffdio_wake w = { .range = { .start = base, .len = 4096 }};
                             ioctl(uffd_fd, UFFDIO_WAKE, &w);
                        } else {
                            perror("[DSM] Emergency zeropage failed");
                        }
                    }
                    continue; 
                }
            }

            /* ... åç»­çš„ç½‘ç»œæ”¶å‘ã€å†…å­˜å¡«å……é€»è¾‘ä¿æŒä¸å˜ ... */
            uint64_t req = htobe64(base);
            if (send(sock, &req, 8, 0) != 8) {
                close_socket_locked(owner);
                pthread_mutex_unlock(&conn_locks[owner]);
                continue;
            }
            int total = PAGE_SIZE * PREFETCH;
            int recvd = 0;
            bool error = false;
            while (recvd < total) {
                int n = recv(sock, buf + recvd, total - recvd, MSG_WAITALL);
                if (n <= 0) {
                    close_socket_locked(owner); 
                    error = true;
                    break;
                }
                recvd += n;
            }
            pthread_mutex_unlock(&conn_locks[owner]);
            if (error) {
                continue; 
            }
            for(int k=0; k<PREFETCH; k++) {
                struct uffdio_copy c = { .dst = base + k*4096, .src = (uint64_t)(buf + k*4096), .len = 4096, .mode = 0 };
                if (ioctl(uffd_fd, UFFDIO_COPY, &c) < 0) {
                    if (errno == EEXIST) {
                        struct uffdio_wake w = { .start = c.dst, .len = c.len, .mode = 0 };
                        ioctl(uffd_fd, UFFDIO_WAKE, &w);
                    }
                }
            }
        }
    }
    free(buf);
    return NULL;
}


/* [ä¿®æ”¹] åˆå§‹åŒ–å…¥å£ */
void dsm_universal_init(void) {
    signal(SIGPIPE, SIG_IGN); 

    if (access("/sys/module/giantvm_kvm", F_OK) == 0 || access("/dev/giantvm", F_OK) == 0) {
        printf("[GiantVM] KERNEL MODULE DETECTED. Using ORIGINAL FULL-SHARE Mode.\n");
        gvm_mode = 0; 
        return; 
    }

    printf("[GiantVM] NO KERNEL MODULE. Using MEMORY-ONLY Mode (Frontier Fixed).\n");
    gvm_mode = 1; 
    
    // [æ–°å¢] è§£æé…ç½®æ–‡ä»¶
    if (parse_cluster_conf("cluster.conf") != 0) {
        fprintf(stderr, "[GiantVM] Error: Could not load or parse cluster.conf for memory servers. Aborting UFFD init.\n");
        return;
    }

    uffd_fd = syscall(__NR_userfaultfd, O_CLOEXEC | O_NONBLOCK);
    if (uffd_fd < 0) {
        perror("[GiantVM] userfaultfd syscall failed");
        return;
    }

    struct uffdio_api api = { .api = UFFD_API, .features = 0 };
    if (ioctl(uffd_fd, UFFDIO_API, &api) < 0) {
        perror("[GiantVM] uffdio_api failed");
        close(uffd_fd);
        uffd_fd = -1;
        return;
    }
    
    /* [ä¿®æ”¹] ä½¿ç”¨åŠ¨æ€è·å–çš„èŠ‚ç‚¹æ•°é‡è¿›è¡Œåˆ†é… */
    global_sockets = malloc(sizeof(int) * g_node_count);
    conn_locks = malloc(sizeof(pthread_mutex_t) * g_node_count);
    
    if (!global_sockets || !conn_locks) abort(); 

    for(int i=0; i < g_node_count; i++) {
        global_sockets[i] = -1;
        pthread_mutex_init(&conn_locks[i], NULL);
    }

    for(int i=0; i < WORKER_THREADS; i++) {
        qemu_thread_create(NULL, "dsm-w", dsm_worker, NULL, QEMU_THREAD_JOINABLE);
    }
}

/* æ³¨å†Œå†…å­˜åŒºåŸŸ (æ— å˜åŒ–) */
void dsm_universal_register(void *ptr, size_t size) {
    if (gvm_mode == 1 && uffd_fd >= 0) {
        struct uffdio_register r = { 
            .range = {(uint64_t)ptr, size}, 
            .mode = UFFDIO_REGISTER_MODE_MISSING 
        };
        if (ioctl(uffd_fd, UFFDIO_REGISTER, &r) < 0) {
             perror("[GiantVM] register memory failed");
        }
    }
}
```

#### C. ä»£ç æ³¨å…¥ç‚¹ (Injection Points)

1.  **æ–‡ä»¶ `vl.c` (Main Loop):**
    *   åœ¨æ–‡ä»¶å¤´æ·»åŠ ï¼š`#include "dsm_backend.h"`
    *   åœ¨ `main` å‡½æ•°ä¸­ï¼Œæ‰¾åˆ°æ‰¾åˆ°å¦‚ä¸‹éƒ¨åˆ†ï¼š
        ```c
            configure_accelerator(current_machine)

            /* æ’å…¥ä½ç½® */
            dsm_universal_init(); 

            if (qtest_chrdev) {
                qtest_init(qtest_chrdev, qtest_log, &error_fatal);
            }
        ```

2.  **æ–‡ä»¶ `exec.c` (Memory Handling):**
    *   åœ¨æ–‡ä»¶å¤´æ·»åŠ ï¼š`#include "dsm_backend.h"`
    *   åœ¨ `ram_block_add` å‡½æ•°ä¸­ï¼Œæ‰¾åˆ° `return 0;` ä¹‹å‰çš„ä½ç½®ï¼Œæ’å…¥ï¼š
        ```c
        if (new_block->host) dsm_universal_register(new_block->host, new_block->max_length);
        ```

3.  **æ–‡ä»¶ `Makefile.objs`:**
    *   æ‰¾åˆ° `common-obj-y += vl.o`ï¼Œåœ¨åé¢æ·»åŠ ï¼š
        ```makefile
        common-obj-y += dsm_backend.o
        ```

---

## 3. å†…å­˜æœåŠ¡ç«¯è„šæœ¬ (Mode B ä¸“ç”¨)
**SO_REUSEPORT å¤šè¿›ç¨‹ç‰ˆ (fast_mem_server.c)**
**æ–‡ä»¶ï¼š** `fast_mem_server.c`

**ã€ä¿®æ”¹ç›®æ ‡ã€‘**
1.  å¼€å¯ `SO_REUSEPORT`ï¼Œå…è®¸å¯åŠ¨å¤šä¸ªè¿›ç¨‹ç»‘å®šåŒä¸€ç«¯å£ã€‚
2.  åˆ©ç”¨å†…æ ¸è‡ªåŠ¨è´Ÿè½½å‡è¡¡è§£å†³å•çº¿ç¨‹ Accept ç“¶é¢ˆã€‚

**ã€å…¨é‡æ–°ä»£ç  / New Fileã€‘**
```c
/* 
 * GiantVM Frontier High-Performance Memory Server (Final Optimized)
 * Feature: 
 * 1. SO_REUSEPORT (Multi-process Load Balancing)
 * 2. Non-blocking State Machine (Anti-Blocking)
 * 3. EPOLLET (Edge Triggered for High Concurrency)
 * 4. Smart Epoll Update (Reduces Syscall Overhead)
 * 
 * Compile: gcc -O3 -o fast_mem_server fast_mem_server.c -lpthread
 * Usage: Run N instances where N = CPU cores.
 */

#define _GNU_SOURCE 
#include <endian.h>
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <unistd.h>
#include <fcntl.h>
#include <sys/socket.h>
#include <sys/epoll.h>
#include <netinet/in.h>
#include <netinet/tcp.h>
#include <sys/mman.h>
#include <errno.h>
#include <signal.h>
#include <stdint.h>

#define MAX_EVENTS 1024
#define MAX_FDS 1048576 
#define PORT 9999
#define PAGE_SIZE 4096
#define PREFETCH 32       // æ¯æ¬¡ä¼ è¾“ 32 é¡µ (128KB)
#define TOTAL_SEND_SIZE (PAGE_SIZE * PREFETCH)
#define MEM_FILE "physical_ram.img"

/* 
 * [çŠ¶æ€ç»“æ„ä½“]
 * å¢åŠ  current_events ç”¨äºç¼“å­˜å½“å‰ Epoll çŠ¶æ€ï¼Œå‡å°‘ç³»ç»Ÿè°ƒç”¨
 */
typedef struct {
    /* è¯»å–é˜¶æ®µçš„çŠ¶æ€ */
    uint8_t head_buf[8];
    int head_read_len;

    /* å‘é€é˜¶æ®µçš„çŠ¶æ€ */
    int is_sending;       // 0: ç­‰å¾…è¯·æ±‚, 1: æ­£åœ¨å‘é€
    uint64_t req_base;    // å®¢æˆ·ç«¯è¯·æ±‚çš„åœ°å€
    size_t sent_len;      // å·²ç»å‘é€äº†å¤šå°‘å­—èŠ‚
    
    /* [ä¼˜åŒ–æ ¸å¿ƒ] è®°å½•å½“å‰ Epoll ç›‘å¬çš„äº‹ä»¶ */
    uint32_t current_events; 
} conn_state_t;

static conn_state_t *states = NULL;
static char *mem_ptr = NULL;
static off_t file_size = 0;

/* è®¾ç½®éé˜»å¡æ¨¡å¼ */
int set_nonblocking(int fd) {
    int flags = fcntl(fd, F_GETFL, 0);
    if (flags == -1) return -1;
    return fcntl(fd, F_SETFL, flags | O_NONBLOCK);
}

/* 
 * [æ™ºèƒ½æ›´æ–°å‡½æ•°] 
 * åªæœ‰å½“éœ€è¦çš„äº‹ä»¶å’Œå½“å‰ä¸ä¸€è‡´æ—¶ï¼Œæ‰è°ƒç”¨ epoll_ctlã€‚
 * è¿™æå¤§åœ°å‡å°‘äº†é«˜é¢‘äº¤äº’ä¸‹çš„ä¸Šä¸‹æ–‡åˆ‡æ¢å¼€é”€ã€‚
 */
void smart_update_epoll(int epollfd, int fd, conn_state_t *st, uint32_t new_events) {
    if (st->current_events == new_events) {
        return; /* çŠ¶æ€æœªå˜ï¼Œç›´æ¥è¿”å›ï¼Œ0å¼€é”€ */
    }
    
    struct epoll_event ev;
    ev.events = new_events;
    ev.data.fd = fd;
    if (epoll_ctl(epollfd, EPOLL_CTL_MOD, fd, &ev) == 0) {
        st->current_events = new_events;
    }
}

int main() {
    signal(SIGPIPE, SIG_IGN);
    int listen_sock, conn_sock, nfds, epollfd;
    struct epoll_event ev, events[MAX_EVENTS];
    struct sockaddr_in addr;
    socklen_t addrlen = sizeof(addr);

    /* 1. å†…å­˜åˆå§‹åŒ– */
    states = (conn_state_t *)calloc(MAX_FDS, sizeof(conn_state_t));
    if (!states) { perror("calloc"); return 1; }

    int fd_mem = open(MEM_FILE, O_RDONLY);
    if (fd_mem < 0) { perror("open mem file"); return 1; }
    file_size = lseek(fd_mem, 0, SEEK_END);
    mem_ptr = mmap(NULL, file_size, PROT_READ, MAP_SHARED, fd_mem, 0);
    if (mem_ptr == MAP_FAILED) { perror("mmap"); return 1; }
    
    /* å»ºè®®å†…æ ¸é¢„è¯» */
    madvise(mem_ptr, file_size, MADV_HUGEPAGE | MADV_WILLNEED);

    /* 2. ç½‘ç»œåˆå§‹åŒ– */
    listen_sock = socket(AF_INET, SOCK_STREAM, 0);
    int opt = 1;
    setsockopt(listen_sock, SOL_SOCKET, SO_REUSEADDR, &opt, sizeof(opt));
    /* [å…³é”®] å¼€å¯ REUSEPORT å…è®¸å¤šè¿›ç¨‹ç»‘å®šåŒä¸€ç«¯å£ */
    setsockopt(listen_sock, SOL_SOCKET, SO_REUSEPORT, &opt, sizeof(opt)); 

    addr.sin_family = AF_INET;
    addr.sin_addr.s_addr = INADDR_ANY;
    addr.sin_port = htons(PORT);

    if (bind(listen_sock, (struct sockaddr *)&addr, sizeof(addr)) < 0) { perror("bind"); return 1; }
    if (listen(listen_sock, 20000) < 0) { perror("listen"); return 1; }

    epollfd = epoll_create1(0);
    ev.events = EPOLLIN;
    ev.data.fd = listen_sock;
    epoll_ctl(epollfd, EPOLL_CTL_ADD, listen_sock, &ev);

    printf("[*] Server PID %d ready on port %d (Optimized)\n", getpid(), PORT);

    /* 3. äº‹ä»¶ä¸»å¾ªç¯ */
    while (1) {
        nfds = epoll_wait(epollfd, events, MAX_EVENTS, -1);
        
        for (int n = 0; n < nfds; ++n) {
            int fd = events[n].data.fd;

            /* Case A: æ–°è¿æ¥ (Accept Loop for EPOLLET) */
            if (fd == listen_sock) {
                while (1) {
                    conn_sock = accept(listen_sock, (struct sockaddr *)&addr, &addrlen);
                    if (conn_sock == -1) {
                        if (errno == EAGAIN || errno == EWOULDBLOCK) break; // å¤„ç†å®Œæ‰€æœ‰ç§¯å‹è¿æ¥
                        break;
                    }
                    
                    if (conn_sock >= MAX_FDS) {
                        close(conn_sock);
                        continue;
                    }

                    set_nonblocking(conn_sock);
                    int flag = 1;
                    setsockopt(conn_sock, IPPROTO_TCP, TCP_NODELAY, &flag, sizeof(int));
                    
                    // åˆå§‹åŒ–çŠ¶æ€
                    memset(&states[conn_sock], 0, sizeof(conn_state_t));
                    
                    // åˆå§‹åŒ–å½“å‰äº‹ä»¶è®°å½•
                    states[conn_sock].current_events = EPOLLIN | EPOLLET;
                    
                    ev.events = EPOLLIN | EPOLLET;
                    ev.data.fd = conn_sock;
                    epoll_ctl(epollfd, EPOLL_CTL_ADD, conn_sock, &ev);
                }
                continue;
            }

            /* Case B: å·²æœ‰è¿æ¥çš„æ•°æ®å¤„ç† (State Machine) */
            conn_state_t *st = &states[fd];
            int done_work = 0; 

            while (1) {
                done_work = 0;

                /* --- é˜¶æ®µ 1: è¯»å–è¯·æ±‚å¤´ (8å­—èŠ‚) --- */
                if (!st->is_sending) {
                    int to_read = 8 - st->head_read_len;
                    if (to_read > 0) {
                        ssize_t r = recv(fd, st->head_buf + st->head_read_len, to_read, 0);
                        if (r > 0) {
                            st->head_read_len += r;
                            done_work = 1; 
                            if (st->head_read_len == 8) {
                                // è§£æå¤´
                                uint64_t req_be;
                                memcpy(&req_be, st->head_buf, 8);
                                st->req_base = be64toh(req_be);
                                if (st->req_base + TOTAL_SEND_SIZE > file_size) st->req_base = 0;
                                
                                st->is_sending = 1;
                                st->sent_len = 0;
                                st->head_read_len = 0;
                            }
                        } else if (r == -1) {
                            if (errno != EAGAIN && errno != EWOULDBLOCK) {
                                close(fd); goto reset_state; // å‡ºé”™
                            }
                            // EAGAIN: è¯»ç¼“å†²åŒºç©ºäº†ï¼Œç¨åé‡è¯•
                        } else {
                            close(fd); goto reset_state; // å¯¹ç«¯å…³é—­
                        }
                    }
                }

                /* --- é˜¶æ®µ 2: å‘é€æ•°æ® --- */
                if (st->is_sending) {
                    char *data_start = mem_ptr + st->req_base;
                    size_t remain = TOTAL_SEND_SIZE - st->sent_len;
                    
                    ssize_t s = send(fd, data_start + st->sent_len, remain, MSG_DONTWAIT);

                    if (s > 0) {
                        st->sent_len += s;
                        done_work = 1;
                        
                        if (st->sent_len == TOTAL_SEND_SIZE) {
                            // å‘é€å®Œæ¯•
                            st->is_sending = 0;
                            
                            /* 
                             * [æ™ºèƒ½ä¿®æ­£]ï¼šå‘é€å®Œæ¯•ï¼Œå¿…é¡»ç¡®ä¿ EPOLLOUT è¢«å…³é—­ã€‚
                             * å¦‚æœä¹‹å‰å› ä¸ºç¼“å†²åŒºæ»¡æ‰“å¼€äº† EPOLLOUTï¼Œè¿™é‡Œä¼šè°ƒç”¨ç³»ç»Ÿè°ƒç”¨å…³é—­å®ƒã€‚
                             * å¦‚æœä¸€ç›´é¡ºç•…ï¼Œè¿™é‡Œä»€ä¹ˆéƒ½ä¸åšã€‚
                             */
                            smart_update_epoll(epollfd, fd, st, EPOLLIN | EPOLLET);
                            
                            // å…³é”®ï¼šPipeline æœºåˆ¶ï¼Œç»§ç»­å¾ªç¯å°è¯•è¯»å–ä¸‹ä¸€ä¸ªè¯·æ±‚
                            continue; 
                        }
                    } else if (s == -1) {
                        if (errno == EAGAIN || errno == EWOULDBLOCK) {
                            /* 
                             * å‘é€ç¼“å†²åŒºæ»¡ï¼Œå¿…é¡»å¼€å¯ EPOLLOUT ç›‘å¬ã€‚
                             * å†…æ ¸ä¼šåœ¨ç¼“å†²åŒºå¯å†™æ—¶å†æ¬¡å”¤é†’æˆ‘ä»¬ã€‚
                             */
                            smart_update_epoll(epollfd, fd, st, EPOLLIN | EPOLLOUT | EPOLLET);
                            break; // é€€å‡ºå†…éƒ¨å¾ªç¯ï¼Œäº¤è¿˜ CPU
                        }
                        close(fd); goto reset_state;
                    }
                }

                /* 
                 * é€€å‡ºæ¡ä»¶ï¼š
                 * å¦‚æœè¿™ä¸€è½®å¾ªç¯æ—¢æ²¡æœ‰è¯»åˆ°æœ‰æ•ˆæ•°æ®ï¼ˆrecv EAGAINï¼‰ï¼Œ
                 * ä¹Ÿæ²¡æœ‰æˆåŠŸå‘é€æ•°æ®ï¼ˆsend EAGAIN æˆ– æ²¡åœ¨å‘ï¼‰ï¼Œ
                 * è¯´æ˜ socket æš‚æ—¶æ²¡æœ‰æ´»åŠ¨ï¼Œé€€å‡ºå¾ªç¯ã€‚
                 */
                if (!done_work) break;
            }
            continue;
            
            reset_state:
            states[fd].head_read_len = 0;
            states[fd].is_sending = 0;
            states[fd].sent_len = 0;
            // è¿æ¥å…³é—­åï¼Œå†…æ ¸ä¼šè‡ªåŠ¨ä» epoll set ä¸­ç§»é™¤ï¼Œæ— éœ€æ‰‹åŠ¨ epoll_ctl DEL
        }
    }
    return 0;
}
```

---

## 4.å®Œæ•´éƒ¨ç½²æµç¨‹

#### 0. åŸºç¡€ç¯å¢ƒä¸ä¾èµ–å®‰è£… (æ‰€æœ‰èŠ‚ç‚¹)
**æ‰€æœ‰èŠ‚ç‚¹ï¼ˆç‰©ç†æœºæˆ–è™šæ‹Ÿæœºï¼‰å‡éœ€æ‰§è¡Œï¼Œè¿™æ˜¯æˆåŠŸéƒ¨ç½²çš„åŸºç¡€ã€‚**

```bash
# 1. å®‰è£…åŸºç¡€ç¼–è¯‘å·¥å…· (Kernel & QEMU)
sudo apt-get update
sudo apt-get install -y build-essential libncurses-dev bison flex libssl-dev libelf-dev \
    pkg-config libglib2.0-dev libpixman-1-dev libpython3-dev libaio-dev libcap-ng-dev \
    libattr1-dev libcap-dev python3-venv python3-pip

# 2. å…³é”®å†…æ ¸å‚æ•°è°ƒä¼˜ (å†™å…¥ /etc/sysctl.conf ä»¥æ°¸ä¹…ç”Ÿæ•ˆ)
# è¿™äº›å‚æ•°æ˜¯ä¸ºäº†åº”å¯¹ä¸‡èŠ‚ç‚¹è§„æ¨¡ä¸‹çš„é«˜å¹¶å‘è¿æ¥ã€å¤§é‡æ–‡ä»¶å¥æŸ„å’Œé«˜ç½‘ç»œååã€‚
cat <<EOF | sudo tee -a /etc/sysctl.conf
# --- æ–‡ä»¶å¥æŸ„ä¸å†…å­˜æ˜ å°„ ---
fs.file-max = 2097152
vm.max_map_count = 262144

# --- ç½‘ç»œæ ¸å¿ƒä¸è¿æ¥é˜Ÿåˆ— ---
net.core.somaxconn = 65535
net.core.netdev_max_backlog = 65536

# --- TCP å†…å­˜ä¸ç¼“å†²åŒº ---
# å¢å¤§äº†TCPè¯»å†™ç¼“å†²åŒºï¼Œä»¥é€‚åº”é«˜å»¶è¿Ÿã€é«˜å¸¦å®½ç½‘ç»œ
net.ipv4.tcp_mem = 4194304 6291456 8388608
net.ipv4.tcp_wmem = 4096 131072 4194304
net.ipv4.tcp_rmem = 4096 131072 6291456
net.ipv4.tcp_moderate_rcvbuf = 1

# --- TCP è¿æ¥ç®¡ç† ---
net.ipv4.ip_local_port_range = 1024 65535
net.ipv4.tcp_max_syn_backlog = 65536
net.ipv4.tcp_tw_reuse = 1
net.ipv4.tcp_fin_timeout = 15
net.ipv4.tcp_max_orphans = 262144
net.ipv4.tcp_syn_retries=2

# --- ARP è¡¨ä¸è¿æ¥è·Ÿè¸ª ---
net.ipv4.neigh.default.gc_thresh1 = 8192
net.ipv4.neigh.default.gc_thresh2 = 16384
net.ipv4.neigh.default.gc_thresh3 = 32768
net.netfilter.nf_conntrack_max = 2097152
net.nf_conntrack_max = 2097152

# --- [æ–°å¢] æ‹¥å¡æ§åˆ¶ç®—æ³• ---
# ä½¿ç”¨ BBR ç®—æ³•ï¼Œèƒ½æ›´å¥½åœ°å¤„ç†å»¶è¿Ÿå’Œä¸¢åŒ…ï¼Œæå‡åå
net.core.default_qdisc=fq
net.ipv4.tcp_congestion_control=bbr

# --- [æ–°å¢] å†…æ ¸ç´§æ€¥å†…å­˜é¢„ç•™ (é’ˆå¯¹DSMæ¨¡å¼) ---
# ä¸º GFP_ATOMIC åˆ†é…é¢„ç•™æ›´å¤šå†…å­˜ï¼Œé™ä½å†…æ ¸åœ¨é«˜å‹ä¸‹å› å†…å­˜ä¸è¶³è€Œå´©æºƒçš„é£é™©
vm.min_free_kbytes = 1048576
EOF

# åº”ç”¨æ‰€æœ‰ sysctl å‚æ•°
sudo sysctl -p

# 3. ç½‘ç»œä¸ç”¨æˆ·å¥æŸ„é™åˆ¶
# å°†ä»¥ä¸‹å†…å®¹è¿½åŠ åˆ° /etc/security/limits.conf ä»¥æ°¸ä¹…æé«˜ç”¨æˆ·çº§èµ„æºé™åˆ¶
cat <<EOF | sudo tee -a /etc/security/limits.conf
* soft nofile 1048576
* hard nofile 1048576
* soft nproc 1048576
* hard nproc 1048576
EOF
# æ³¨æ„ï¼šlimits.conf çš„ä¿®æ”¹éœ€è¦é‡æ–°ç™»å½• Shell æ‰èƒ½ç”Ÿæ•ˆã€‚

# 4. [å…³é”®] é…ç½®å·¨å‹å¸§ (Jumbo Frames)
# ç”±äºå†…æ ¸DSMæ¨¡å¼çš„åè®®å¤´è¾ƒå¤§(>1300å­—èŠ‚)ï¼Œå¿…é¡»å¼€å¯å·¨å‹å¸§é¿å…IPåˆ†ç‰‡ã€‚
# å°† <interface> æ›¿æ¢ä¸ºä½ çš„ä¸»ç½‘å¡å (å¦‚ eth0, enp3s0)
sudo ip link set dev <interface> mtu 9000

```
**éªŒè¯ï¼š** `ip a` å‘½ä»¤åº”æ˜¾ç¤ºä½ çš„ç½‘å¡ `mtu 9000`ã€‚`sysctl net.ipv4.tcp_congestion_control` åº”æ˜¾ç¤º `bbr`ã€‚

---

#### æµç¨‹ Aï¼šåŸç‰ˆå…¨å…±äº«æ¨¡å¼ (DSM Mode)
**é€‚ç”¨åœºæ™¯ï¼š** åˆ†å¸ƒå¼æ“ä½œç³»ç»Ÿç ”ç©¶ã€è·¨èŠ‚ç‚¹å†…å­˜/CPU èšåˆã€‚
**æ¶æ„ï¼š** L0 (ç‰©ç†æœº) -> L1 (GiantVM å®¿ä¸»æœºé›†ç¾¤) -> L2 (GiantVM å®¢æˆ·æœº)ã€‚

**æ­¥éª¤ 1ï¼šL0/L1 ç¯å¢ƒç¡®è®¤**
1.  **å†…æ ¸ä¸ç½‘ç»œè°ƒä¼˜ï¼š** ç¡®ä¿æ‰€æœ‰å‚ä¸é›†ç¾¤çš„ç‰©ç†æœºï¼ˆL0ï¼‰å’Œè™šæ‹Ÿæœºï¼ˆL1ï¼‰éƒ½å·²å®Œæˆä¸Šè¿° **â€œ0. åŸºç¡€ç¯å¢ƒä¸ä¾èµ–å®‰è£…â€** ä¸­çš„æ‰€æœ‰æ­¥éª¤ã€‚
2.  **å…³é—­ Watchdogï¼ˆå»ºè®®ï¼‰ï¼š**
    è™½ç„¶ä»£ç ä¸­å·²åŠ å…¥ `touch_watchdog` é€»è¾‘ï¼Œä½†åœ¨ä¸‡èŠ‚ç‚¹å¹¿æ’­ç­‰æç«¯æƒ…å†µä¸‹ï¼Œå…³é—­å†…æ ¸çš„æ­»é”æ£€æµ‹å¯ä»¥é¿å…ä¸å¿…è¦çš„é‡å¯ã€‚
    ```bash
    sudo sysctl -w kernel.nmi_watchdog=0
    sudo sysctl -w kernel.softlockup_panic=0
    ```

**æ­¥éª¤ 2ï¼šç¼–è¯‘ä¸åŠ è½½å†…æ ¸æ¨¡å— (æ‰€æœ‰ L1 èŠ‚ç‚¹)**
```bash
# è¿›å…¥ä¿®æ”¹åçš„å†…æ ¸æºç ç›®å½•
cd giantvm-kvm/

# ç¼–è¯‘å†…æ ¸æ¨¡å—
make -j$(nproc)

# åŠ è½½æ¨¡å—
sudo insmod giantvm-kvm.ko

# éªŒè¯åŠ è½½æˆåŠŸ
lsmod | grep giantvm
dmesg | tail
```
*åº”èƒ½çœ‹åˆ° `giantvm_kvm` æ¨¡å—ä¿¡æ¯ã€‚*

**æ­¥éª¤ 3ï¼šé…ç½®é›†ç¾¤ (æ‰€æœ‰ L1 èŠ‚ç‚¹)**
åˆ›å»ºä¸€ä¸ªå†…å®¹å®Œå…¨ç›¸åŒçš„ `cluster.conf` æ–‡ä»¶ï¼Œåˆ†å‘åˆ°æ‰€æœ‰ L1 èŠ‚ç‚¹ä¸Š QEMU çš„å¯åŠ¨ç›®å½•ã€‚
```text
# æ ¼å¼: ID IP PORT
0 192.168.1.101 9999
1 192.168.1.102 9999
2 192.168.1.103 9999
...
10239 192.168.1.10340 9999
```

**æ­¥éª¤ 4ï¼šå¯åŠ¨ GiantVM (æ¯ä¸ª L1 èŠ‚ç‚¹)**
åœ¨æ¯ä¸ª L1 èŠ‚ç‚¹ä¸Šï¼Œè¿›å…¥ç¼–è¯‘å¥½çš„ QEMU ç›®å½•ï¼Œè¿è¡Œå¯¹åº”çš„å¯åŠ¨å‘½ä»¤ã€‚
*æ³¨æ„ï¼šæ¯ä¸ªèŠ‚ç‚¹çš„ `-giantvm-id` **å¿…é¡»å”¯ä¸€**ï¼Œä¸”ä¸ `cluster.conf` ä¸­çš„ ID å¯¹åº”ã€‚*

```bash
# åœ¨ 192.168.1.101 ä¸Š (Node 0)
./qemu-system-x86_64 \
  -enable-kvm \
  -m 4G \
  -smp 4 \
  -giantvm-id 0 \
  -giantvm-cluster ./cluster.conf \
  -drive file=disk.qcow2,format=qcow2 \
  -netdev tap,id=n1,ifname=tap0,script=no,downscript=no \
  -device virtio-net-pci,netdev=n1 \
  -vnc :0

# åœ¨ 192.168.1.102 ä¸Š (Node 1)
./qemu-system-x86_64 ... -giantvm-id 1 ... -giantvm-cluster ./cluster.conf ...
```

**éªŒè¯ï¼š**
åœ¨å„ä¸ª L1 èŠ‚ç‚¹ä¸Šæ‰§è¡Œ `dmesg`ï¼Œåº”èƒ½çœ‹åˆ°å¤§é‡ `[DSM] Connection established to node X` ç­‰è¿æ¥å»ºç«‹çš„æ—¥å¿—ã€‚è™šæ‹Ÿæœº L2 å¯åŠ¨åï¼Œå…¶å†…å­˜å’Œ CPU èµ„æºåº”æ˜¯åˆ†å¸ƒå¼çš„ã€‚

---

#### æµç¨‹ Bï¼šåŒæ¨¡ UFFD å†…å­˜æ¨¡å¼ (Frontier Mode)
**é€‚ç”¨åœºæ™¯ï¼š** ä¸‡èŠ‚ç‚¹äº‘æ¸¸æˆã€GPU ç›´é€šã€é«˜æ€§èƒ½è®¡ç®—ã€‚
**æ¶æ„ï¼š** L0 (ç‰©ç†æœº) åˆ†ä¸ºä¸¤ç§è§’è‰²ï¼šå°‘æ•°**å­˜å‚¨èŠ‚ç‚¹**å’Œå¤§é‡**è®¡ç®—èŠ‚ç‚¹**ã€‚

**æ­¥éª¤ 1ï¼šæœåŠ¡ç«¯ (Memory Server) å¯åŠ¨**
åœ¨ä¸“ç”¨çš„**å­˜å‚¨èŠ‚ç‚¹**ä¸Šæ‰§è¡Œï¼š

*   **1. å‡†å¤‡ç¯å¢ƒï¼š**
    ç¡®ä¿å·²å®Œæˆ **â€œ0. åŸºç¡€ç¯å¢ƒä¸ä¾èµ–å®‰è£…â€** çš„æ‰€æœ‰æ­¥éª¤ã€‚ç‰¹åˆ«æ³¨æ„ `ulimit` é™åˆ¶éœ€è¦æ–°å¼€ä¸€ä¸ª Shell æ‰èƒ½ç”Ÿæ•ˆã€‚
    ```bash
    # ä¸´æ—¶æé«˜å½“å‰ Shell çš„æ–‡ä»¶å¥æŸ„é™åˆ¶
    ulimit -n 1048576
    ```

*   **2. ç¼–è¯‘æœåŠ¡ç«¯ï¼š**
    ```bash
    # å°†æ–¹æ¡ˆä¸­çš„ C ä»£ç ä¿å­˜ä¸º fast_mem_server.c
    gcc -O3 -o fast_mem_server fast_mem_server.c -lpthread
    ```

*   **3. ç”Ÿæˆå†…å­˜é•œåƒæ–‡ä»¶ï¼š**
    ä¾‹å¦‚ï¼Œåˆ›å»ºä¸€ä¸ª 64GB çš„å†…å­˜é•œåƒã€‚
    ```bash
    fallocate -l 64G physical_ram.img
    ```

*   **4. [å…³é”®] å¯åŠ¨å¤šè¿›ç¨‹æœåŠ¡ç«¯ï¼š**
    ä¸ºäº†å……åˆ†åˆ©ç”¨å¤šæ ¸ CPU å¤„ç†æµ·é‡å¹¶å‘è¿æ¥ï¼Œå¿…é¡»å¯åŠ¨ä¸ CPU æ ¸å¿ƒæ•°ç›¸å½“çš„æœåŠ¡è¿›ç¨‹ã€‚è¿™äº›è¿›ç¨‹ä¼šé€šè¿‡ `SO_REUSEPORT` å…±åŒç›‘å¬ 9999 ç«¯å£ã€‚
    ```bash
    # ä»¥åå°æ¨¡å¼å¯åŠ¨ N ä¸ªæœåŠ¡è¿›ç¨‹ï¼ŒN = CPUæ ¸å¿ƒæ•°
    for i in $(seq 1 $(nproc)); do
        nohup ./fast_mem_server > server_log_${i}.txt 2>&1 &
    done

    # éªŒè¯è¿›ç¨‹æ˜¯å¦å…¨éƒ¨å¯åŠ¨
    pgrep fast_mem_server | wc -l
    ```
    *åº”çœ‹åˆ°ä¸ CPU æ ¸å¿ƒæ•°ç›¸åŒçš„è¿›ç¨‹æ•°é‡ã€‚*

**æ­¥éª¤ 2ï¼šå®¢æˆ·ç«¯ (Compute Node) å‡†å¤‡**
åœ¨æ‰€æœ‰**è®¡ç®—èŠ‚ç‚¹**ä¸Šæ‰§è¡Œï¼š

*   **1. ç¡®ä¿å†…æ ¸æ¨¡å—æœªåŠ è½½ï¼š**
    ```bash
    sudo rmmod giantvm-kvm || true # å¿½ç•¥é”™è¯¯
    lsmod | grep giantvm # ç¡®ä¿æ— è¾“å‡º
    ```

*   **2. [ä¿®æ”¹] åˆ›å»ºå¹¶åˆ†å‘ `cluster.conf` æ–‡ä»¶ï¼š**
    åˆ›å»ºä¸€ä¸ª `cluster.conf` æ–‡ä»¶ï¼Œå†…å®¹**åªåŒ…å«ä½ çš„å†…å­˜æœåŠ¡å™¨ï¼ˆå­˜å‚¨èŠ‚ç‚¹ï¼‰çš„IPåœ°å€**ã€‚ç„¶åå°†è¿™ä¸ªæ–‡ä»¶åˆ†å‘åˆ°æ‰€æœ‰è®¡ç®—èŠ‚ç‚¹çš„QEMUå¯åŠ¨ç›®å½•ä¸‹ã€‚
    ```text
    # 
    # Frontier Mode çš„ cluster.conf
    # è¿™é‡Œåªéœ€è¦åˆ—å‡ºå†…å­˜æœåŠ¡å™¨ã€‚ID å’Œ PORT å­—æ®µä¼šè¢«è§£æä½†ä¸ä¼šè¢«ä½¿ç”¨ï¼Œä½†æ ¼å¼å¿…é¡»ä¿æŒä¸€è‡´ã€‚
    # å†…å­˜é¡µåˆ°æœåŠ¡å™¨çš„æ˜ å°„å…³ç³»å°†é€šè¿‡ (é¡µé¢å· % æœåŠ¡å™¨æ€»æ•°) æ¥å†³å®šã€‚
    #
    0 192.168.1.101 9999  # å†…å­˜æœåŠ¡å™¨ 1
    1 192.168.1.102 9999  # å†…å­˜æœåŠ¡å™¨ 2
    # å¦‚æœæœ‰æ›´å¤šå†…å­˜æœåŠ¡å™¨ï¼Œç»§ç»­æ·»åŠ ...
    ```

*   **3. ç¼–è¯‘ QEMU (å¸¦æ‰©å®¹æ”¯æŒ)ï¼š**
    ```bash
    cd qemu/
    make clean
    
    ./configure \
      --target-list=x86_64-softmmu \
      --enable-kvm \
      --enable-vnc \
      --disable-werror \
      --extra-cflags="-O3 -D__FD_SETSIZE=65536 -DFD_SETSIZE=65536" \
      --python=/usr/bin/python3

    make -j$(nproc)
    ```

**æ­¥éª¤ 3ï¼šå¯åŠ¨å®¢æˆ·ç«¯**
åœ¨æ¯ä¸ªè®¡ç®—èŠ‚ç‚¹ä¸Šè¿è¡Œ QEMUã€‚**è¯·ç¡®ä¿ `cluster.conf` æ–‡ä»¶ä½äºä½ æ‰§è¡Œqemuå‘½ä»¤çš„å½“å‰ç›®å½•ä¸‹ã€‚**
```bash
# ç¡®ä¿ cluster.conf åœ¨å½“å‰ç›®å½•
ls cluster.conf 

sudo ./qemu-system-x86_64 \
  -name GiantVM-Frontier \
  -machine type=q35,accel=kvm \
  -cpu host \
  -smp 8 \
  -m 16G \
  -vga std \
  -vnc :0 \
  -netdev user,id=n1 \
  -device virtio-net-pci,netdev=n1
```
**éªŒè¯ï¼š**
1.  å¯åŠ¨ QEMU æ—¶ï¼Œæ§åˆ¶å°é™¤äº†æ‰“å° `[GiantVM] NO KERNEL MODULE...` ä¹‹å¤–ï¼Œè¿˜ä¼šæ–°å¢ä¸€è¡Œæ—¥å¿—ï¼š`[GiantVM] Loaded 2 memory server IPs from cluster.conf` ï¼ˆæ•°å­— `2` å–å†³äºä½ çš„é…ç½®æ–‡ä»¶å†…å®¹ï¼‰ã€‚
2.  å¦‚æœ QEMU æŠ¥é”™ `[GiantVM] Failed to open cluster.conf`ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä»¥åŠæƒé™æ˜¯å¦æ­£ç¡®ã€‚
3.  åç»­è¡Œä¸ºä¸ä¹‹å‰ä¸€è‡´ï¼ŒVM å¯åŠ¨æ—¶ä¼šä» `cluster.conf` ä¸­åˆ—å‡ºçš„æœåŠ¡å™¨æ‹‰å–å†…å­˜ã€‚

---


## 5.æ•ˆç‡å¯¹æ¯”ä¸ GPU è°ƒç”¨

**åŸºå‡†ï¼š** ç‰©ç†æœº (i9/4090) = 100%ã€‚

| æ¨¡å¼ | å­æ¨¡å¼ | è§¦å‘æ¡ä»¶ | CPU æ•ˆç‡ | GPU æ€§èƒ½ | å†…å­˜æ€§èƒ½ | GPU è°ƒç”¨æ–¹å¼ |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| **åŸç‰ˆå…¨å…±äº«** | **KVM** | åŠ è½½å†…æ ¸æ¨¡å— | **1%~10%** | **0%** | 50Âµs å»¶è¿Ÿ | **æ— æ³•ç›´æ¥è°ƒç”¨**ã€‚<br>åˆ†å¸ƒå¼ CPU ä¸æ”¯æŒ PCIe ç›´é€šï¼Œæ›¿ä»£æ–¹æ¡ˆè§ä¸‹ã€‚ |
| **åªå…±äº«å†…å­˜** | **KVM** | æ— æ¨¡å— + æœ‰ KVM | **98%** | **98%** | 50Âµs å»¶è¿Ÿ | **VFIO ç›´é€š**ã€‚<br>ä»…ä¸»èŠ‚ç‚¹æ˜¾å¡å·¥ä½œï¼Œç©æ¸¸æˆä¸“ç”¨ã€‚ |
| **åªå…±äº«å†…å­˜** | **TCG** | æ— æ¨¡å— + æ—  KVM | **5%** | **0%** | 50Âµs å»¶è¿Ÿ | **è½¯ä»¶æ¨¡æ‹Ÿ**ã€‚<br>Virtio-GPUï¼Œæ— æ³•ç©æ¸¸æˆã€‚ |

**æ€»ç»“ï¼š**
*   **åŸç‰ˆå…¨å…±äº«æ¨¡å¼ï¼š** æ”¯æŒ CPU/Mem åˆ†å¸ƒå¼ï¼Œä½† GPU æ— æ³•ä½¿ç”¨ï¼Œé€Ÿåº¦ææ…¢ã€‚
*   **åªå…±äº«å†…å­˜æ¨¡å¼ï¼š** æ”¾å¼ƒ CPU åˆ†å¸ƒå¼ï¼Œæ¢å– GPU ç›´é€šå’ŒåŸç”Ÿ CPU é€Ÿåº¦ã€‚**è¿™æ˜¯å”¯ä¸€èƒ½ç©æ¸¸æˆçš„æ–¹æ¡ˆã€‚**

## 6.åŸç‰ˆæ¨¡å¼è¿è¡Œ Star Citizen

ä¸ºäº†è®©ã€Šæ˜Ÿé™…å…¬æ°‘ã€‹ï¼ˆStar Citizenï¼Œä¸€æ¬¾å¯¹ I/O å’Œå†…å­˜ååæå…¶æ•æ„Ÿçš„æ¸¸æˆï¼‰åœ¨ GiantVM åŸç‰ˆæ¨¡å¼ä¸‹è¾¾åˆ°**â€œå¯ç©ï¼ˆPlayableï¼‰â€**çš„æé™ï¼ˆæ¯”å¦‚ 15-30 FPSï¼Œæ“ä½œå»¶è¿Ÿ < 100msï¼‰ï¼Œä½ å¿…é¡»è¿›è¡Œä¸€åœº**â€œå…¨é“¾è·¯æè‡´å‹æ¦¨â€**çš„é…ç½®ã€‚

ä»¥ä¸‹æ˜¯é’ˆå¯¹ä½ è¿™ä¸ªç‰¹æ®Šç¯å¢ƒçš„**ç»ˆæä¼˜åŒ–æ–¹æ¡ˆ**ï¼š

---

#### ç¬¬ä¸€å±‚ï¼šç‰©ç†å±‚ä¸ç½‘ç»œå±‚ï¼ˆRDMA è°ƒä¼˜ï¼‰
*ç›®æ ‡ï¼šæŠŠç‰©ç†å»¶è¿Ÿå‹åˆ°ç‰©ç†æé™ï¼Œè®© DSM åè®®è·‘åœ¨å…‰é€Ÿä¸Šã€‚*

1.  **ç¡¬ä»¶è¦æ±‚ï¼š**
    *   å¿…é¡»ä½¿ç”¨æ”¯æŒ **RoCE v2** æˆ– **InfiniBand** çš„ç½‘å¡ï¼ˆConnectX-4 æˆ–æ›´é«˜ï¼‰ã€‚
    *   äº¤æ¢æœºå¿…é¡»é…ç½® **PFC (Priority Flow Control)** å’Œ **ECN**ï¼Œä¿è¯ RDMA æµé‡æ— ä¸¢åŒ…ï¼ˆæ— æŸç½‘ç»œï¼‰ã€‚GiantVM çš„ DSM åè®®æå…¶è„†å¼±ï¼Œä¸€æ—¦ä¸¢åŒ…å¯¼è‡´ TCP é‡ä¼ ï¼ˆæˆ–è€… RDMA é‡ä¼ ï¼‰ï¼Œæ¸¸æˆä¼šç¬é—´å¡æ­» 200ms ä»¥ä¸Šã€‚
2.  **MTU å·¨å¸§ï¼š**
    *   æ‰€æœ‰èŠ‚ç‚¹ï¼ˆL0 å’Œ L1ï¼‰çš„ MTU å¿…é¡»è®¾ä¸º **9000**ï¼ˆç”šè‡³æ›´é«˜ï¼Œå¦‚æœ IB æ”¯æŒï¼‰ã€‚å‡å°‘åŒ…å¤´å¼€é”€ï¼Œæé«˜æœ‰æ•ˆè½½è·ã€‚
3.  **CPU ç»‘æ ¸ (Pinning)ï¼š**
    *   **æå…¶é‡è¦ã€‚** RDMA Polling çº¿ç¨‹å¿…é¡»ç‹¬å ç‰©ç†æ ¸å¿ƒã€‚
    *   åœ¨ L0 å®¿ä¸»æœºä¸Šï¼Œå°† L1 è™šæ‹Ÿæœºçš„ vCPU ä¸ç‰©ç†æ ¸å¿ƒ **1:1 ç»‘å®š**ã€‚
    *   é˜²æ­¢å®¿ä¸»æœºè°ƒåº¦å™¨æŠŠå¤„ç† DSM çš„çº¿ç¨‹åˆ‡èµ°ï¼Œå“ªæ€•åˆ‡èµ° 1msï¼Œå¯¹æ¸¸æˆæ¥è¯´å°±æ˜¯æ‰å¸§ã€‚

---

#### ç¬¬äºŒå±‚ï¼šL1 å®¿ä¸»æœºå±‚ï¼ˆGPU ä¾›ç»™ä¾§ï¼‰
*ç›®æ ‡ï¼šè®© GPU æ¸²æŸ“å®Œç›´æ¥æ¨æµï¼Œç»å¯¹ä¸è¦å†™å›è™šæ‹Ÿæœºï¼*

è¿™æ˜¯**æœ€æ ¸å¿ƒ**çš„ç­–ç•¥å˜æ›´ã€‚åƒä¸‡ä¸è¦è®© VirtualGL æŠŠæ¸²æŸ“å¥½çš„ç”»é¢é€šè¿‡ç½‘ç»œä¼ å› GiantVM çš„ Windows æ¡Œé¢æ˜¾ç¤ºã€‚
**å› ä¸ºï¼šæ¸²æŸ“å›å†™ = å·¨é‡å†…å­˜å†™å…¥ = å·¨é‡ DSM åŒæ­¥ = å´©æºƒã€‚**

**æ­£ç¡®åšæ³•ï¼š** é‡‡ç”¨â€œ**è®¡ç®—ä¸æ˜¾ç¤ºåˆ†ç¦»**â€æ¶æ„ã€‚

1.  **L1 èŠ‚ç‚¹é…ç½® (GPU Server)ï¼š**
    *   é…ç½®å¥½ **VirtualGL** æœåŠ¡ç«¯ã€‚
    *   é…ç½® **TurboVNC** æˆ– **Sunshine** (æ¨è)ã€‚
    *   **å…³é”®æ“ä½œï¼š** åœ¨ L1 èŠ‚ç‚¹ä¸Šç›´æ¥å¯åŠ¨ä¸€ä¸ª X Serverï¼ˆå¸¦ GPU åŠ é€Ÿï¼‰ï¼Œç”¨æ¥æ‰¿è½½ GiantVM å‘æ¥çš„æ¸²æŸ“æŒ‡ä»¤ã€‚

2.  **æ˜¾ç¤ºè¾“å‡ºè·¯å¾„ï¼ˆæ—è·¯æ¨æµï¼‰ï¼š**
    *   **ä¸è¦**åœ¨ GiantVM (L2) é‡Œé¢çœ‹ç”»é¢ã€‚
    *   ä½ éœ€è¦åœ¨ **L1 èŠ‚ç‚¹** ä¸Šè¿è¡Œæ¨æµæœåŠ¡ï¼ˆSunshine/Moonlight Hostï¼‰ã€‚
    *   **æ•°æ®æµå‘ï¼š**
        1.  GiantVM (CPU) å‘å‡º OpenGL/Vulkan æŒ‡ä»¤ ->
        2.  VirtualGL æ‹¦æˆª ->
        3.  å‘ç»™ L1 èŠ‚ç‚¹çš„ GPU æ¸²æŸ“ ->
        4.  **æ¸²æŸ“ç»“æœç›´æ¥å­˜å…¥ L1 çš„æ˜¾å­˜/å†…å­˜** ->
        5.  Sunshine (è¿è¡Œåœ¨ L1) ç›´æ¥æ•è· L1 çš„å±å¹•/æ˜¾å­˜ ->
        6.  ç¼–ç è§†é¢‘æµ ->
        7.  é€šè¿‡æ™®é€š TCP/UDP å‘é€åˆ°ä½ æ‰‹é‡Œçš„ç‰©ç†æ˜¾ç¤ºç»ˆç«¯ï¼ˆæ‰‹æœº/PCï¼‰ã€‚

    *   **ç»“æœï¼š** è¿™ä¸€è·¯ä¸‹æ¥ï¼Œ**æ²¡æœ‰ä¸€å¸§ç”»é¢æ•°æ®ç»è¿‡ GiantVM çš„ DSM åè®®**ã€‚GiantVM åªè´Ÿè´£å¤„ç†é¼ æ ‡è¾“å…¥å’Œæ¸¸æˆé€»è¾‘ï¼ˆç‰©ç†ç¢°æ’ã€AIï¼‰ï¼Œè´Ÿè½½é™ä½ 90%ã€‚

---

#### ç¬¬ä¸‰å±‚ï¼šGiantVM L2 å†…éƒ¨ï¼ˆWindows å‡è‚¥ï¼‰
*ç›®æ ‡ï¼šæ¶ˆç­ä¸€åˆ‡ä¸å¿…è¦çš„å†…å­˜å†™å…¥ã€‚*

Windows 10 å¯¹ GiantVM æ¥è¯´æ˜¯â€œå™ªéŸ³ä¹‹ç‹â€ã€‚å¿…é¡»è¿›è¡Œå¤–ç§‘æ‰‹æœ¯å¼é˜‰å‰²ï¼š

1.  **ç³»ç»Ÿç‰ˆæœ¬ï¼š**
    *   åŠ¡å¿…ä½¿ç”¨ **Windows 10 LTSC** æˆ– **Tiny10**ï¼ˆé­”æ”¹ç²¾ç®€ç‰ˆï¼‰ã€‚ä¸è¦ç”¨æ™®é€šçš„ Home/Pro ç‰ˆã€‚
2.  **æœåŠ¡ç¦ç”¨ï¼ˆå¿…é¡»ï¼‰ï¼š**
    *   `Windows Defender` (å®æ—¶æ‰«æä¼šç–¯ç‹‚è¯»å†™å†…å­˜ï¼Œå¿…å…³)ã€‚
    *   `SysMain` (åŸ Superfetchï¼Œä¼šé¢„åŠ è½½å†…å­˜ï¼Œå¯¼è‡´ä¸å¿…è¦çš„ DSM æµé‡)ã€‚
    *   `Windows Search` (ç´¢å¼•æ–‡ä»¶ï¼Œå¡é¡¿æº)ã€‚
    *   `Windows Update`ã€‚
3.  **å†…å­˜æœºåˆ¶ï¼š**
    *   **å…³é—­è™šæ‹Ÿå†…å­˜ (Pagefile):** å½»åº•å…³é—­ã€‚å¼ºè¿« Windows åªç”¨ RAMã€‚å› ä¸ºå¦‚æœå‘ç”Ÿ Swapï¼Œå°±æ˜¯â€œåœ¨ç½‘ç»œå†…å­˜ä¸Šçš„è™šæ‹Ÿç£ç›˜ä¸Šè¿›è¡Œæ¢é¡µâ€ï¼Œé€Ÿåº¦ä¼šæ…¢åˆ°ç³»ç»Ÿé™æ­¢ã€‚
4.  **ç½‘ç»œé©±åŠ¨ (Virtio)ï¼š**
    *   ä½¿ç”¨æœ€æ–°çš„ NetKVM é©±åŠ¨ï¼Œå¹¶å¼€å¯å¤šé˜Ÿåˆ— (Multiqueue)ã€‚

---

#### ç¬¬å››å±‚ï¼šæ¸¸æˆé…ç½®ï¼ˆæ˜Ÿé™…å…¬æ°‘ç‰¹è°ƒï¼‰
*ç›®æ ‡ï¼šå‡å°‘ I/O è¯·æ±‚ã€‚*

1.  **æ¸¸æˆå®‰è£…ä½ç½®ï¼š**
    *   **ç»å¯¹ä¸èƒ½**æ”¾åœ¨åŸºäº QCOW2 çš„è™šæ‹Ÿç£ç›˜ä¸Šã€‚
    *   **æ–¹æ¡ˆ A (åœŸè±ª)ï¼š** ç»™ GiantVM åˆ†é… 128GB å†…å­˜ï¼Œåˆ›å»ºä¸€ä¸ª **Ramdisk**ï¼ŒæŠŠã€Šæ˜Ÿé™…å…¬æ°‘ã€‹æ‹·è¿›å»è¿è¡Œã€‚è¿™æ˜¯æœ€å¿«çš„ï¼ŒI/O é€Ÿåº¦ç­‰äºå†…å­˜é€Ÿåº¦ã€‚
    *   **æ–¹æ¡ˆ B (å¸¸è§„)ï¼š** åœ¨ L1 å®¿ä¸»æœºä¸ŠæŒ‚è½½ NVMe SSDï¼Œé€šè¿‡ `virtio-scsi` (é…ç½® `iothread`) é€ä¼ ç»™ GiantVMã€‚
2.  **r_DisplayInfo = 3ï¼š**
    *   è¿›æ¸¸æˆç¬¬ä¸€æ—¶é—´å¼€å¯æ€§èƒ½ç›‘è§†ï¼Œå…³æ³¨ CPU å»¶è¿Ÿã€‚
3.  **é™ä½ç‰©ç†è®¡ç®—é¢‘ç‡ï¼š**
    *   å¦‚æœå¯èƒ½ï¼Œé™ä½æ¸¸æˆçš„åˆ†è¾¨ç‡å’Œç‰©ç†æ•ˆæœã€‚è™½ç„¶ GPU åœ¨ L1 è·‘å¾—é£å¿«ï¼Œä½† CPU (è·‘åœ¨ GiantVM é‡Œ) éœ€è¦å¤„ç†ç‰©ç†ç¢°æ’æ•°æ®ã€‚å¦‚æœ CPU ç®—ä¸è¿‡æ¥ï¼ŒGPU æ¸²æŸ“å†å¿«ä¹Ÿæ²¡ç”¨ã€‚

---

#### æœ€ç»ˆæ¶æ„å›¾ï¼ˆPlayable Configurationï¼‰

```text
ã€ä½ çš„ç‰©ç†æœº/å®¢æˆ·ç«¯ã€‘(è¿è¡Œ Moonlight Client)
       ^
       | (h.264/h.265 è§†é¢‘æµï¼Œç»•è¿‡ GiantVM)
       |
ã€L1 å®¿ä¸»æœº (Node 1)ã€‘ <---(RDMA æé€ŸåŒæ­¥)---> ã€L1 å®¿ä¸»æœº (Node 0)ã€‘
   |  [NVIDIA 4090]                                  |
   |  (è¿è¡Œ X Server + VirtualGL Server)              |
   |  (è¿è¡Œ Sunshine æ¨æµæœåŠ¡)                         |
   |                                                 |
   +-------------------------------------------------+
           | (VirtualGL ä¼ è¾“æ¸²æŸ“æŒ‡ä»¤)
           v
   ã€GiantVM L2 (Windows 10)ã€‘
      - è¿è¡Œ Star Citizen.exe (CPU é€»è¾‘)
      - æ‹¦æˆª GPU è°ƒç”¨ -> å‘é€ç»™ L1
      - å†…å­˜ï¼šåˆ†å¸ƒåœ¨ Node0/1 ä¸Š (RDMA åŠ é€Ÿ)
      - ç£ç›˜ï¼šRamdisk (é¿å… I/O))
```

#### é¢„æœŸæ•ˆæœè¯„ä¼°

*   **å¸§ç‡ (FPS):** å¦‚æœ L1 çš„æ˜¾å¡å¤Ÿå¼ºï¼Œä¸”ä½¿ç”¨äº†ä¸Šè¿°â€œæ—è·¯æ¨æµâ€æ–¹æ¡ˆï¼Œç”»é¢æœ¬èº«å¯ä»¥è¾¾åˆ° **30-60 FPS**ã€‚
*   **æ“ä½œå»¶è¿Ÿ:** çº¦ **50-80ms**ï¼ˆSunshine ç¼–ç å»¶è¿Ÿ + ç½‘ç»œä¼ è¾“ï¼‰ã€‚
*   **å¡é¡¿ (Stuttering):** ä¾ç„¶ä¼šå­˜åœ¨ã€‚æ¯å½“æ¸¸æˆåŠ è½½æ–°èµ„äº§ï¼ˆè¿›å…¥æ–°åŒºåŸŸã€åˆ·å‡ºæ–°é£èˆ¹ï¼‰æ—¶ï¼ŒCPU éœ€è¦åˆ†é…æ–°å†…å­˜ï¼Œè¿™ä¼šè§¦å‘ DSM é”ï¼Œå¯¼è‡´ç¬é—´æ‰å¸§ã€‚
*   **ç»“è®º:** è¿™æ˜¯ä¸€ä¸ª**â€œå¯ä»¥èµ·é£ï¼Œå¯ä»¥çœ‹é£æ™¯ï¼Œä½†æ‰“ç©ºæˆ˜å¯èƒ½ä¼šè¾“â€**çš„çŠ¶æ€ã€‚

**ä¸€å¥è¯æ€»ç»“é…ç½®æ ¸å¿ƒï¼š**
**ç”¨ RDMA æ•‘ CPU å’Œå†…å­˜ï¼Œç”¨ Sunshine+VirtualGL æ—è·¯æ¨æµæ•‘æ˜¾å¡ï¼Œç”¨ Ramdisk æ•‘ç¡¬ç›˜ã€‚** ç¥ä½ å¥½è¿ï¼Œå…¬æ°‘ï¼
